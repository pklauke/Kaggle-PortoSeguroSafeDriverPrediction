{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook trains a number of algorithms for the Kaggle competition: https://www.kaggle.com/c/porto-seguro-safe-driver-prediction. The goal of this competition is to find out whether a driver will make a claim or not. Due to the fact that the data is anonymized feature engineering is difficult. Therefore my solution focuses mainly on emsembling a variety of models using blending.\n",
    "\n",
    "This notebook uses XGBoost, LightGBM, CatBoost and Regularized Greedy Forest. In another notebook a Field-Aware Factorization Machine is trained aswell. Due to the fact that Field-Aware Factoriztation Machines are very different from tree-based algorithms its features are engineered independently. At last 3 different public kernels are added to the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc \n",
    "from multiprocessing import *\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595212 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin       ...        \\\n",
       "0              0              0              1              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "2              0              0              0              1       ...         \n",
       "3              0              1              0              0       ...         \n",
       "4              0              1              0              0       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "print('{} rows'.format(len(df_train)))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892816 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "0   0          0              1          8              1              0   \n",
       "1   1          4              2          5              1              0   \n",
       "2   2          5              1          3              0              0   \n",
       "3   3          0              1          6              0              0   \n",
       "4   4          5              1          7              0              0   \n",
       "\n",
       "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin       ...        \\\n",
       "0              0              1              0              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "2              0              0              0              1       ...         \n",
       "3              1              0              0              0       ...         \n",
       "4              0              0              0              1       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           1           1           1          12               0   \n",
       "1           2           0           3          10               0   \n",
       "2           4           0           2           4               0   \n",
       "3           5           1           0           5               1   \n",
       "4           4           0           0           4               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               0               1               1               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               1               1               0               0   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               1  \n",
       "2               0  \n",
       "3               0  \n",
       "4               1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "print('{} rows'.format(len(df_test)))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFWCAYAAAD0cJ6OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X1w1NXh7/HPZh+iZjdNYkM7qSwFNaB2AiQ7AcsCwk9v\nijNWtAgk92I7CBQU+oMfYAiFxHh5LJPYkTSjVp2xjCQm4PhQO9eH8BBDmEBTAyOY1lI1QNSJAe1u\nkCTsfu8fHVNzfxJyMZsle96vv8zJ2W/OYTaTt+e7m9gsy7IEAACMFRftBQAAgOgiBgAAMBwxAACA\n4YgBAAAMRwwAAGA4YgAAAMM5InnxJ598Unv27FF3d7dyc3OVnZ2tNWvWyGaz6cYbb1RRUZHi4uJU\nVVWlyspKORwOLVmyRNOmTdP58+e1evVqtbe3KyEhQVu3blVKSoqampq0ceNG2e12+f1+LV26VJJU\nVlamffv2yeFwaO3atcrIyIjk1gAAiBkROxloaGjQO++8o4qKCu3YsUOffPKJNm/erOXLl2vnzp2y\nLEs1NTVqa2vTjh07VFlZqWeeeUalpaXq6upSRUWF0tPTtXPnTs2cOVPl5eWSpKKiIpWUlKiiokJH\njhzR8ePHdezYMR06dEjV1dUqLS1VcXFxpLYFAEDMidjJQF1dndLT0/XQQw8pGAzq4YcfVlVVlbKz\nsyVJU6ZM0YEDBxQXF6fx48fL5XLJ5XLJ6/WqublZjY2NWrBgQc/c8vJyBYNBdXV1yev1SpL8fr/q\n6+vlcrnk9/tls9mUlpamUCikM2fOKCUl5aLra2sLRGrrGATJydfo7Nlz0V4GYBy+94au1FTPRT8X\nsRg4e/asWltb9cQTT+jUqVNasmSJLMuSzWaTJCUkJCgQCCgYDMrj+fcCExISFAwGe41/fa7b7e41\n9+TJk4qPj1dSUlKv8UAg0GcMJCdfI4fDPtDbxiDq64kNIHL43os9EYuBpKQkjRo1Si6XS6NGjVJ8\nfLw++eSTns93dHQoMTFRbrdbHR0dvcY9Hk+v8b7mJiYmyul0fuM1+kLZDm2pqR5Od4Ao4Htv6Oor\n4iL2moGsrCy9/fbbsixLn376qb788kvdeuutamhokCTV1tbK5/MpIyNDjY2N6uzsVCAQ0IkTJ5Se\nnq7MzEzt37+/Z25WVpbcbrecTqdaWlpkWZbq6urk8/mUmZmpuro6hcNhtba2KhwO93kqAAAA/i1i\nJwPTpk3T4cOHNWvWLFmWpcLCQl133XVav369SktLNWrUKOXk5Mhut2vevHnKy8uTZVlasWKF4uPj\nlZubq/z8fOXm5srpdKqkpESSVFxcrFWrVikUCsnv92vs2LGSJJ/Ppzlz5igcDquwsDBS2wIAIObY\nTP2rhRxzDW0cVQLRwffe0BWV2wQAAGBoIAYAADAcMQAAgOEi+uuIAQC4Es3fsmdAr/fsmukDer3B\nxskAAABD0D//+YXeeOP/DMi1iAEAAIagv//9fR04sH9ArsVtAgAAIqyz87w2bSrWJ598ou7ubv3n\nf67Uyy+/qNbW0wqFQpo793/qP/7jf2jp0kVavXqtRoz4oV56aZfa29t155136ZFHfq1hw76n06dP\n6eabb9GqVQX6wx+e1d///r5efvlF3X33vd9qfcQAAAAR9tJLu/X976epuHizTp5sUU3NG0pKSlJh\n4f/WuXMdmj//fykrK/uijz95skWPPVam+PirNHv23Wpv/0z33z9fL7+8+1uHgEQMxKyBfnEMBs9Q\nfyESgP+upeUjTZz4Y0nS8OFetbe3y+f71w//a65J0A9/OFKnT5/q9Ziv/0rAH/zgOl1zTYIk6dpr\nv6uurq4BXR+vGQAAIMJGjBip9947Lkk6ffqU3nrrdR09+o4k6dy5Dp04cUJpaWlyueLV3v6ZJOlv\nf2vuefxXf/H36+Li4hQOD8wvEeZkAABgnME+gbv77nu1efOjWrp0kUKhkEpKHteLL1ZryZIH1NnZ\nqfnzFyo5OUX33TdHJSVb9L3vfV/f/W5qn9f8wQ+u0z/+8XdVVe3U7Nl532p9/G2CGMVtgqGL2wS4\nkvG3CYYu/jYBAAC4KGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDhiAEAAAxHDAAAYDhi\nAAAAwxEDAAAYjhgAAMBwxAAAAIYjBgAAMBwxAACA4YgBAAAMRwwAAGA4YgAAAMMRAwAAGI4YAADA\ncMQAAACGIwYAADAcMQAAgOGIAQAADEcMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwnCOS\nF7/nnnvkdrslSdddd50WL16sNWvWyGaz6cYbb1RRUZHi4uJUVVWlyspKORwOLVmyRNOmTdP58+e1\nevVqtbe3KyEhQVu3blVKSoqampq0ceNG2e12+f1+LV26VJJUVlamffv2yeFwaO3atcrIyIjk1gAA\niBkRi4HOzk5ZlqUdO3b0jC1evFjLly/XhAkTVFhYqJqaGo0bN047duzQ7t271dnZqby8PE2aNEkV\nFRVKT0/XsmXL9Nprr6m8vFzr1q1TUVGRtm/fruHDh2vRokU6fvy4LMvSoUOHVF1drY8//ljLli3T\n7t27I7U1AABiSsRioLm5WV9++aXmz5+vCxcu6L/+67907NgxZWdnS5KmTJmiAwcOKC4uTuPHj5fL\n5ZLL5ZLX61Vzc7MaGxu1YMGCnrnl5eUKBoPq6uqS1+uVJPn9ftXX18vlcsnv98tmsyktLU2hUEhn\nzpxRSkpKpLYHAEDMiFgMXHXVVXrggQd033336cMPP9TChQtlWZZsNpskKSEhQYFAQMFgUB6Pp+dx\nCQkJCgaDvca/Pver2w5fjZ88eVLx8fFKSkrqNR4IBPqMgeTka+Rw2Ad628C3lprqufQkIIp4jsae\niMXAyJEjNWLECNlsNo0cOVJJSUk6duxYz+c7OjqUmJgot9utjo6OXuMej6fXeF9zExMT5XQ6v/Ea\nfTl79txAbRUYUG1tgWgvAbio1FQPz9Ehqq+Ii9i7CXbt2qUtW7ZIkj799FMFg0FNmjRJDQ0NkqTa\n2lr5fD5lZGSosbFRnZ2dCgQCOnHihNLT05WZman9+/f3zM3KypLb7ZbT6VRLS4ssy1JdXZ18Pp8y\nMzNVV1encDis1tZWhcNhbhEAANBPETsZmDVrlgoKCpSbmyubzaZNmzYpOTlZ69evV2lpqUaNGqWc\nnBzZ7XbNmzdPeXl5sixLK1asUHx8vHJzc5Wfn6/c3Fw5nU6VlJRIkoqLi7Vq1SqFQiH5/X6NHTtW\nkuTz+TRnzhyFw2EVFhZGalsAAMQcm2VZVrQXEQ2xfsw1f8ueaC8Bl+nZNdOjvQTgorhNMHRF5TYB\nAAAYGogBAAAMRwwAAGA4YgAAAMMRAwAAGI4YAADAcMQAAACGIwYAADAcMQAAgOGIAQAADEcMAABg\nOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDhiAEAAAxHDAAAYDhiAAAAwxEDAAAYjhgA\nAMBwxAAAAIYjBgAAMBwxAACA4YgBAAAMRwwAAGA4YgAAAMMRAwAAGI4YAADAcMQAAACGIwYAADAc\nMQAAgOGIAQAADEcMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDhIhoD7e3tmjp1\nqk6cOKGPPvpIubm5ysvLU1FRkcLhsCSpqqpK9957r2bPnq29e/dKks6fP69ly5YpLy9PCxcu1Jkz\nZyRJTU1Nuu+++zR37lyVlZX1fJ2ysjLNmjVLc+fO1dGjRyO5JQAAYk7EYqC7u1uFhYW66qqrJEmb\nN2/W8uXLtXPnTlmWpZqaGrW1tWnHjh2qrKzUM888o9LSUnV1damiokLp6enauXOnZs6cqfLycklS\nUVGRSkpKVFFRoSNHjuj48eM6duyYDh06pOrqapWWlqq4uDhSWwIAICZFLAa2bt2quXPnatiwYZKk\nY8eOKTs7W5I0ZcoU1dfX6+jRoxo/frxcLpc8Ho+8Xq+am5vV2NioyZMn98w9ePCggsGgurq65PV6\nZbPZ5Pf7VV9fr8bGRvn9ftlsNqWlpSkUCvWcJAAAgEuLSAy8+OKLSklJ6fmBLkmWZclms0mSEhIS\nFAgEFAwG5fF4euYkJCQoGAz2Gv/6XLfb3WtuX+MAAKB/HJG46O7du2Wz2XTw4EG99957ys/P7/V/\n6x0dHUpMTJTb7VZHR0evcY/H02u8r7mJiYlyOp3feI1LSU6+Rg6HfSC2Cwyo1NRLP3+BaOI5Gnsi\nEgPPP/98z3/PmzdPjzzyiLZt26aGhgZNmDBBtbW1mjhxojIyMvTb3/5WnZ2d6urq0okTJ5Senq7M\nzEzt379fGRkZqq2tVVZWltxut5xOp1paWjR8+HDV1dVp6dKlstvt2rZtmx544AF98sknCofDSklJ\nueQaz549F4mtA99aWxsnW7hypaZ6eI4OUX1FXERi4Jvk5+dr/fr1Ki0t1ahRo5STkyO73a558+Yp\nLy9PlmVpxYoVio+PV25urvLz85Wbmyun06mSkhJJUnFxsVatWqVQKCS/36+xY8dKknw+n+bMmaNw\nOKzCwsLB2hIAADHBZlmWFe1FREOsl+38LXuivQRcpmfXTI/2EoCL4mRg6OrrZIBfOgQAgOGIAQAA\nDEcMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDhiAEAAAxHDAAAYDhiAAAAwxED\nAAAYjhgAAMBwxAAAAIYjBgAAMBwxAACA4YgBAAAMRwwAAGA4YgAAAMMRAwAAGI4YAADAcMQAAACG\nIwYAADAcMQAAgOGIAQAADEcMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDhiAEA\nAAxHDAAAYDhiAAAAw/UrBlpaWvTKK6/IsiytX79eP/vZz/TnP/850msDAACDoF8xUFBQIKfTqZqa\nGn344YcqKCjQb37zm0ivDQAADIJ+xUBnZ6dmzJihvXv36q677pLP59OFCxcivTYAADAI+hUDdrtd\nr7/+uvbt26fbbrtNb731luLieLkBAACxoF8/0R999FHt27dPhYWFGjZsmF577TVt2LAh0msDAACD\nwNGfSS+88IJmzJihiRMnSpIee+yxiC4KAAAMnn7FgM/n05/+9Cc9+uijSk9P17Rp0zR16lQNGzbs\noo8JhUJat26dPvjgA9lsNhUXFys+Pl5r1qyRzWbTjTfeqKKiIsXFxamqqkqVlZVyOBxasmSJpk2b\npvPnz2v16tVqb29XQkKCtm7dqpSUFDU1NWnjxo2y2+3y+/1aunSpJKmsrEz79u2Tw+HQ2rVrlZGR\nMTD/QgAAxLh+xcCdd96pO++8UxcuXNCuXbu0fft2FRYW6r333rvoY/bu3StJqqysVENDgx577DFZ\nlqXly5drwoQJKiwsVE1NjcaNG6cdO3Zo9+7d6uzsVF5eniZNmqSKigqlp6dr2bJleu2111ReXq51\n69apqKhI27dv1/Dhw7Vo0SIdP35clmXp0KFDqq6u1scff6xly5Zp9+7dA/MvBABAjOtXDDz99NM6\nfPiw3n//fd10001asGBBzy2Di7n99tt12223SZJaW1uVmJio+vp6ZWdnS5KmTJmiAwcOKC4uTuPH\nj5fL5ZLL5ZLX61Vzc7MaGxu1YMGCnrnl5eUKBoPq6uqS1+uVJPn9ftXX18vlcsnv98tmsyktLU2h\nUEhnzpxRSkrK5f67AABgjH7FQE1NjU6fPq2f/vSnmjhxorKysnT11Vdf+uIOh/Lz8/Xmm2/q8ccf\n14EDB2Sz2SRJCQkJCgQCCgaD8ng8PY9JSEhQMBjsNf71uW63u9fckydPKj4+XklJSb3GA4FAnzGQ\nnHyNHA57f7YPDKrUVM+lJwFRxHM09vQrBioqKnTu3DkdPnxYBw8e1KZNm5SYmKjKyspLPnbr1q1a\ntWqVZs+erc7Ozp7xjo4OJSYmyu12q6Ojo9e4x+PpNd7X3MTERDmdzm+8Rl/Onj3Xn60Dg66tLRDt\nJQAXlZrq4Tk6RPUVcf16a+FXIVBfX68DBw4oMTFRU6ZM6fMxL730kp588klJ0tVXXy2bzaYf/ehH\namhokCTV1tbK5/MpIyNDjY2N6uzsVCAQ0IkTJ5Senq7MzEzt37+/Z25WVpbcbrecTqdaWlpkWZbq\n6urk8/mUmZmpuro6hcNhtba2KhwOc4sAAIB+slmWZV1q0o9//GPdeuutmjp1qvx+f79+0J47d04F\nBQX67LPPdOHCBS1cuFDXX3+91q9fr+7ubo0aNUobNmyQ3W5XVVWVXnjhBVmWpV/+8pfKycnRl19+\nqfz8fLW1tcnpdKqkpESpqalqamrSpk2bFAqF5Pf7tWLFCknS9u3bVVtbq3A4rIKCAvl8vj7XF+tl\nO3/LnmgvAZfp2TXTo70E4KI4GRi6+joZ6FcMhMNhvf/++zp8+LAuXLigiRMnasyYMQO6yMEW609m\nYmDoIgZwJSMGhq5vfZvg1Vdf1UMPPaRTp06ptbVVDz74oHbt2jVgCwQAANHTrxcQPvvss6qurlZy\ncrIkafHixbr//vs1a9asiC4OAABEXr9OBsLhcE8ISFJKSkrPWwQBAMDQ1q+TgdGjR2vjxo09JwG7\ndu0a8q8ZAAAA/9KvGOju7pbL5dLatWtlWZYmTJigoqKiSK8NAAAMgn7FwKlTp7Rx40atXr060usB\nAACDrF8xEBcXp+nTp2vkyJGKj4/vGf/DH/4QsYUBAIDB0a8Y4EQAAIDY1a8Y+OovDQIAgNjTr7cW\nAgCA2EUMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDhiAEAAAxHDAAAYDhiAAAA\nwxEDAAAYjhgAAMBwxAAAAIYjBgAAMBwxAACA4YgBAAAMRwwAAGA4YgAAAMMRAwAAGI4YAADAcMQA\nAACGIwYAADAcMQAAgOGIAQAADEcMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDh\niAEAAAzniMRFu7u7tXbtWp0+fVpdXV1asmSJbrjhBq1Zs0Y2m0033nijioqKFBcXp6qqKlVWVsrh\ncGjJkiWaNm2azp8/r9WrV6u9vV0JCQnaunWrUlJS1NTUpI0bN8put8vv92vp0qWSpLKyMu3bt08O\nh0Nr165VRkZGJLYFAEBMikgMvPLKK0pKStK2bdv0+eefa+bMmRozZoyWL1+uCRMmqLCwUDU1NRo3\nbpx27Nih3bt3q7OzU3l5eZo0aZIqKiqUnp6uZcuW6bXXXlN5ebnWrVunoqIibd++XcOHD9eiRYt0\n/PhxWZalQ4cOqbq6Wh9//LGWLVum3bt3R2JbAADEpIjEwE9+8hPl5ORIkizLkt1u17Fjx5SdnS1J\nmjJlig4cOKC4uDiNHz9eLpdLLpdLXq9Xzc3Namxs1IIFC3rmlpeXKxgMqqurS16vV5Lk9/tVX18v\nl8slv98vm82mtLQ0hUIhnTlzRikpKZHYGgAAMSciMZCQkCBJCgaD+tWvfqXly5dr69atstlsPZ8P\nBAIKBoPyeDy9HhcMBnuNf32u2+3uNffkyZOKj49XUlJSr/FAIHDJGEhOvkYOh33A9gwMlNRUz6Un\nAVHEczT2RCQGJOnjjz/WQw89pLy8PN11113atm1bz+c6OjqUmJgot9utjo6OXuMej6fXeF9zExMT\n5XQ6v/Eal3L27LmB2CYw4NraAtFeAnBRqakenqNDVF8RF5F3E3z22WeaP3++Vq9erVmzZkmSbr75\nZjU0NEiSamtr5fP5lJGRocbGRnV2dioQCOjEiRNKT09XZmam9u/f3zM3KytLbrdbTqdTLS0tsixL\ndXV18vl8yszMVF1dncLhsFpbWxUOh7lFAADA/4eInAw88cQT+uc//6ny8nKVl5dLkn79619rw4YN\nKi0t1ahRo5STkyO73a558+YpLy9PlmVpxYoVio+PV25urvLz85Wbmyun06mSkhJJUnFxsVatWqVQ\nKCS/36+xY8dKknw+n+bMmaNwOKzCwsJIbAkAgJhlsyzLivYioiHWj7nmb9kT7SXgMj27Znq0lwBc\nFLcJhq5Bv00AAACGDmIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDhiAEAAAxHDAAAYDhi\nAAAAwxEDAAAYjhgAAMBwxAAAAIYjBgAAMBwxAACA4YgBAAAMRwwAAGA4YgAAAMMRAwAAGI4YAADA\ncMQAAACGIwYAADAcMQAAgOGIAQAADEcMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEA\nAIDhiAEAAAxHDAAAYDhiAAAAwxEDAAAYjhgAAMBwxAAAAIYjBgAAMBwxAACA4YgBAAAMRwwAAGC4\niMbAkSNHNG/ePEnSRx99pNzcXOXl5amoqEjhcFiSVFVVpXvvvVezZ8/W3r17JUnnz5/XsmXLlJeX\np4ULF+rMmTOSpKamJt13332aO3euysrKer5OWVmZZs2apblz5+ro0aOR3BIAADEnYjHw+9//XuvW\nrVNnZ6ckafPmzVq+fLl27twpy7JUU1OjtrY27dixQ5WVlXrmmWdUWlqqrq4uVVRUKD09XTt37tTM\nmTNVXl4uSSoqKlJJSYkqKip05MgRHT9+XMeOHdOhQ4dUXV2t0tJSFRcXR2pLAADEpIjFgNfr1fbt\n23s+PnbsmLKzsyVJU6ZMUX19vY4eParx48fL5XLJ4/HI6/WqublZjY2Nmjx5cs/cgwcPKhgMqqur\nS16vVzabTX6/X/X19WpsbJTf75fNZlNaWppCoVDPSQIAALg0R6QunJOTo1OnTvV8bFmWbDabJCkh\nIUGBQEDBYFAej6dnTkJCgoLBYK/xr891u9295p48eVLx8fFKSkrqNR4IBJSSktLn+pKTr5HDYR+Q\nvQIDKTXVc+lJQBTxHI09EYuB/1dc3L8PITo6OpSYmCi3262Ojo5e4x6Pp9d4X3MTExPldDq/8RqX\ncvbsuYHYFjDg2toC0V4CcFGpqR6eo0NUXxE3aO8muPnmm9XQ0CBJqq2tlc/nU0ZGhhobG9XZ2alA\nIKATJ04oPT1dmZmZ2r9/f8/crKwsud1uOZ1OtbS0yLIs1dXVyefzKTMzU3V1dQqHw2ptbVU4HL7k\nqQAAAPi3QTsZyM/P1/r161VaWqpRo0YpJydHdrtd8+bNU15enizL0ooVKxQfH6/c3Fzl5+crNzdX\nTqdTJSUlkqTi4mKtWrVKoVBIfr9fY8eOlST5fD7NmTNH4XBYhYWFg7UlAABigs2yLCvai4iGWD/m\nmr9lT7SXgMv07Jrp0V4CcFHcJhi6rojbBAAA4MpEDAAAYDhiAAAAwxEDAAAYjhgAAMBwxAAAAIYj\nBgAAMBwxAACA4YgBAAAMRwwAAGA4YgAAAMMRAwAAGI4YAADAcMQAAACGIwYAADAcMQAAgOGIAQAA\nDEcMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDhiAEAAAxHDAAAYDhiAAAAwxED\nAAAYjhgAAMBwxAAAAIYjBgAAMBwxAACA4YgBAAAMRwwAAGA4R7QXAACxZP6WPdFeAr6FZ9dMj/YS\nooKTAQAADEcMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwXMz8noFwOKxHHnlEf/3rX+Vy\nubRhwwaNGDEi2ssCAOCKFzMnA2+99Za6urr0wgsvaOXKldqyZUu0lwQAwJAQMzHQ2NioyZMnS5LG\njRund999N8orAgBgaIiZ2wTBYFBut7vnY7vdrgsXLsjh+OYtpqZ6BmtpUfFqyd3RXgJgJL73MBTF\nzMmA2+1WR0dHz8fhcPiiIQAAAP4tZmIgMzNTtbW1kqSmpialp6dHeUUAAAwNNsuyrGgvYiB89W6C\nv/3tb7IsS5s2bdL1118f7WUBAHDFi5kYAAAAlydmbhMAAIDLQwwAAGA4YgAAAMMRAxgywuFwtJcA\nADGJN+Ljinby5Elt3rxZ7777rhwOh8LhsNLT01VQUKCRI0dGe3kAEBN4NwGuaPfff79WrlypsWPH\n9ow1NTVpy5YtqqysjOLKACB2cDKAK1pXV1evEJD+9bcnAETevHnz1N3d3WvMsizZbDZiPMYQA7ii\njR49WgUFBZo8ebI8Ho86Ojq0f/9+jR49OtpLA2LeqlWrtG7dOv3ud7+T3W6P9nIQQdwmwBXNsiy9\n9dZbamxs7PljVJmZmbrjjjtks9mivTwg5j399NMaMWKE7rjjjmgvBRFEDAAAYDjeWggAgOGIAQAA\nDEcMALgsgUBADz74YES/RkFBgU6fPh3RrwGAGABwmb744gs1NzdH9Gs0NDSIlzUBkccLCAFclsWL\nF6uurk5Tp07VDTfcoIMHD+qLL75QcnKytm/frtTUVE2cOFG33HKLPvvsM+3atUuPP/64Xn/9dSUn\nJys1NVXTp0/Xvffeq5deeknPPfecwuGwbrnlFhUVFem5557T448/Lq/Xq+eff17JycnR3jIQszgZ\nAHBZ1q1bp2HDhunhhx/WP/7xD1VWVur111+X1+vVq6++Kkk6e/asFi1apJdffllvv/22Ghsb9cc/\n/lFPPfWUjh8/Lkl6//33VVVVpcrKSr388su69tpr9cwzz2jRokUaNmyYnnrqKUIAiDB+6RCAb2XE\niBHKz89XdXW1PvjgAzU1Ncnr9fZ8/qvfIFlfX68ZM2bI5XLJ5XLp9ttvl/SvWwEfffSRZs+eLUnq\n7u7WzTffPPgbAQxGDAD4Vt59912tXLlSv/jFL5STk6O4uLhe9/mvuuoqSVJcXNw3/uXJUCikGTNm\naN26dZKkjo4OhUKhwVk8AEncJgBwmRwOhy5cuKDDhw8rOztbubm5uuGGG3TgwIFv/GE+adIkvfHG\nG+rq6lIwGNS+fftks9k0YcIEvfnmm2pvb5dlWXrkkUf03HPPSZLsdjthAAwCTgYAXJZrr71WaWlp\n2rNnj86fP6+77rpLTqdTo0eP1qlTp/7b/KlTp+ovf/mL7rnnHn3nO9/RsGHDFB8frzFjxmjp0qX6\n+c9/rnATdJLmAAAAj0lEQVQ4rJtuukmLFi2SJN12221atGiRnn76aQ0fPnywtwgYg3cTABgU77zz\njj788EPdc8896u7u1pw5c7Rp0yaNGTMm2ksDjEcMABgUn3/+uVauXKm2tjZZlqWZM2fqgQceiPay\nAIgYAADAeLyAEAAAwxEDAAAYjhgAAMBwxAAAAIYjBgAAMBwxAACA4f4vY6BD9NHhZq8AAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115541a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train[['target', 'id']].groupby('target').count().rename(columns = {'id': 'count'}).plot(kind = 'bar')\n",
    "plt.ylabel('rows')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding isn't necessary for tree-based algorithms so one hot encoded features are decoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ps_ind_06-09\n",
       "0    234360\n",
       "1    152989\n",
       "2     97568\n",
       "3    110295\n",
       "Name: ps_ind_06-09, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_ps_ind(x):\n",
    "    if x.ps_ind_06_bin == 1:\n",
    "        return 0\n",
    "    elif x.ps_ind_07_bin == 1:\n",
    "        return 1\n",
    "    elif x.ps_ind_08_bin == 1:\n",
    "        return 2\n",
    "    elif x.ps_ind_09_bin == 1:\n",
    "        return 3\n",
    "    else:\n",
    "        return -1\n",
    "df_train['ps_ind_06-09'] = df_train[['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin']] \\\n",
    "                              .apply(decode_ps_ind, axis = 1)\n",
    "df_test['ps_ind_06-09'] = df_test[['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin']] \\\n",
    "                             .apply(decode_ps_ind, axis = 1)\n",
    "\n",
    "df_train.drop(['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin'], axis = 1)\n",
    "df_test.drop(['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin'], axis = 1)\n",
    "\n",
    "df_train.groupby('ps_ind_06-09')['ps_ind_06-09'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Shape:  (595212, 60)\n",
      "After Shape:  (595212, 62)\n",
      "Init Shape:  (892816, 59)\n",
      "After Shape:  (892816, 61)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.replace(-1, np.NaN)\n",
    "d_median = df_train.median(axis=0)\n",
    "d_mean = df_train.mean(axis=0)\n",
    "df_train = df_train.fillna(-1)\n",
    "one_hot = {c: list(df_train[c].unique()) for c in df_train.columns if c not in ['id','target']}\n",
    "\n",
    "def transform_df(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "    return df\n",
    "\n",
    "def multi_transform(df):\n",
    "    print('Init Shape: ', df.shape)\n",
    "    p = Pool(cpu_count())\n",
    "    df = p.map(transform_df, np.array_split(df, cpu_count()))\n",
    "    df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "    p.close(); p.join()\n",
    "    print('After Shape: ', df.shape)\n",
    "    return df\n",
    "\n",
    "df_train = multi_transform(df_train)\n",
    "df_test = multi_transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    best_features = ['ps_ind_03', 'ps_car_13', 'ps_reg_03', 'ps_ind_15']\n",
    "    for i in range(len(best_features)):\n",
    "        for j in range(i+1, len(best_features)):\n",
    "            df[str(best_features[i]+'_times_'+best_features[j])] = df[best_features[i]] * df[best_features[j]]\n",
    "    return df\n",
    "\n",
    "df_train = add_features(df_train)\n",
    "df_test = add_features(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApoAAAJWCAYAAAD4JicwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104f26668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "corr = df_train.corr()\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    " \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 features\n"
     ]
    }
   ],
   "source": [
    "dont_use = ['id', 'target'] + [c for c in df_train.columns if 'calc' in c] + ['ps_ind_11_bin', 'ps_ind_13_bin']\n",
    "label = ['target']\n",
    "\n",
    "#features = df_train.drop(dont_use, axis = 1).columns\n",
    "features = df_train.drop(dont_use + [c for c in df_train.columns if 'times' in c], axis = 1).columns\n",
    "\n",
    "print('{} features'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "cv_splits = 5\n",
    "\n",
    "if False: # only for first use \n",
    "    df_preds_lgb = pd.DataFrame(df_test.copy()['id'])\n",
    "    df_preds_train_lgb = pd.DataFrame(df_train.copy()['id'])\n",
    "\n",
    "for i in range(11):\n",
    "    kf = StratifiedKFold(n_splits = cv_splits, shuffle = True, random_state = 0+i)\n",
    "    cv_scores = []\n",
    "    \n",
    "    preds_lgb = np.zeros(len(df_test))\n",
    "    preds_tr_lgb = np.zeros(len(df_train))\n",
    "    \n",
    "    for train_index, test_index in kf.split(df_train[features], df_train[label].values.ravel()):\n",
    "\n",
    "        X_train = df_train.iloc[train_index, :].loc[:, features]\n",
    "        y_train = df_train.iloc[train_index, :][label].values.ravel()\n",
    "        X_test = df_train.iloc[test_index, :].loc[:, features]\n",
    "        y_test = df_train.iloc[test_index, :][label].values.ravel()\n",
    "\n",
    "        # preparing data\n",
    "        train_data = lgb.Dataset(X_train, label = y_train, free_raw_data=False)\n",
    "        val_data = lgb.Dataset(X_test, label = y_test, free_raw_data=False)\n",
    "\n",
    "        params_lgb = {'objective': 'binary', 'metric': 'AUC', 'boosting': 'gbdt', 'learning_rate': 0.002,\n",
    "                    'verbose': 0, 'num_leaves': 63, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'bagging_seed': i,\n",
    "                    'feature_fraction': 0.9, 'feature_fraction_seed': i, 'max_bin': 16, 'num_rounds': 10000,\n",
    "                    'min_data_in_leaf': 128, 'seed': i, 'lambda_l1': 0, 'lambda_l2': 20}\n",
    "        model_lgb = lgb.train(params_lgb, train_data, valid_sets=[val_data], verbose_eval = None, \n",
    "                              early_stopping_rounds = 250)\n",
    "\n",
    "        preds_valid = model_lgb.predict(X_test)\n",
    "        preds_tr_lgb[test_index] += preds_valid\n",
    "        cv_scores.append(gini_normalized(y_test, preds_valid))\n",
    "        preds_lgb += model_lgb.predict(df_test[features]) / cv_splits\n",
    "        print('Score: {:0.4f}'.format(cv_scores[-1]))\n",
    "    \n",
    "    df_preds_lgb = pd.read_csv('Predictions/Base/lgb/test.csv')\n",
    "    df_preds_lgb[str(i)] = preds_lgb\n",
    "    df_preds_lgb.to_csv('Predictions/Base/lgb/test.csv', index = False)\n",
    "    \n",
    "    df_preds_train_lgb = pd.read_csv('Predictions/Base/lgb/train.csv')\n",
    "    df_preds_train_lgb[str(i)] = preds_tr_lgb\n",
    "    df_preds_train_lgb.to_csv('Predictions/Base/lgb/train.csv', index = False)\n",
    "    \n",
    "    print('CV Score: {:0.4f} +- {:0.4f}'.format(np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "cv_splits = 5\n",
    "\n",
    "if False: #only for first use\n",
    "    df_preds_xgb = pd.DataFrame(df_test.copy()['id'])\n",
    "    df_preds_train_xgb = pd.DataFrame(df_train.copy()['id'])\n",
    "\n",
    "for i in range(5, 6):\n",
    "    kf = StratifiedKFold(n_splits = cv_splits, shuffle = True, random_state = 100+i)\n",
    "\n",
    "    preds_xgb = np.zeros(len(df_test))\n",
    "    preds_tr_xgb = np.zeros(len(df_train))\n",
    "    \n",
    "    cv_scores = []\n",
    "    for train_index, test_index in kf.split(df_train[features], df_train[label].values.ravel()):\n",
    "\n",
    "        X_train = df_train.iloc[train_index, :].loc[:, features]\n",
    "        y_train = df_train.iloc[train_index, :][label].values.ravel()\n",
    "        X_test = df_train.iloc[test_index, :].loc[:, features]\n",
    "        y_test = df_train.iloc[test_index, :][label].values.ravel()\n",
    "\n",
    "        # preparing data\n",
    "        train_data = xgb.DMatrix(X_train, label = y_train)\n",
    "        val_data = xgb.DMatrix(X_test, label = y_test)\n",
    "\n",
    "        params_xgb = {'objective': 'binary:logistic', 'eval_metric': 'auc', 'eta': 0.005\n",
    "                      'subsample': 0.8, 'colsample_bytree': 0.9, 'silent': True, 'max_depth': 3, \n",
    "                      'min_child_weight': 8, 'scale_pos_weight': 1, 'seed': i, \n",
    "                      'gamma': 1.1, 'reg_alpha': 11, 'reg_lambda': 1.0}\n",
    "        watchlist = [(train_data, 'train'), (val_data, 'valid')]\n",
    "        model_xgb = xgb.train(params_xgb, train_data, 25000, watchlist, verbose_eval = None, \n",
    "                              early_stopping_rounds = 250)\n",
    "\n",
    "        preds_valid = model_xgb.predict(xgb.DMatrix(X_test))\n",
    "        preds_tr_xgb[test_index] += preds_valid\n",
    "        cv_scores.append(gini_normalized(y_test, preds_valid))\n",
    "        preds_xgb += model_xgb.predict(xgb.DMatrix(df_test[features])) / cv_splits\n",
    "        print('Score: {:0.4f}'.format(cv_scores[-1]))\n",
    "\n",
    "    print('CV Score: {:0.4f} +- {:0.4f}'.format(np.mean(cv_scores), np.std(cv_scores)))\n",
    "\n",
    "    df_preds_xgb = pd.read_csv('Predictions/Base/xgb/test.csv')\n",
    "    df_preds_xgb[str(i)] = preds_xgb\n",
    "    df_preds_xgb.to_csv('Predictions/Base/xgb/test.csv', index = False)\n",
    "    \n",
    "    df_preds_train_xgb = pd.read_csv('Predictions/Base/xgb/train.csv')\n",
    "    df_preds_train_xgb[str(i)] = preds_tr_xgb\n",
    "    df_preds_train_xgb.to_csv('Predictions/Base/xgb/train.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "cv_splits = 5\n",
    "\n",
    "if False: # only for first use\n",
    "    df_preds_cat = pd.DataFrame(df_test.copy()['id'])\n",
    "    df_preds_train_cat = pd.DataFrame(df_train.copy()['id'])\n",
    "\n",
    "for i in range(5, 6):\n",
    "    kf = StratifiedKFold(n_splits = cv_splits, shuffle = True, random_state = 200+i)\n",
    "    \n",
    "    preds_cat = np.zeros(len(df_test))\n",
    "    preds_tr_cat = np.zeros(len(df_train))\n",
    "    \n",
    "    cv_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(df_train[features], df_train[label].values.ravel()):    \n",
    "        X_train = df_train.iloc[train_index, :].loc[:, features]\n",
    "        y_train = df_train.iloc[train_index, :][label].values.ravel()\n",
    "        X_test = df_train.iloc[test_index, :].loc[:, features]\n",
    "        y_test = df_train.iloc[test_index, :][label].values.ravel()\n",
    "\n",
    "        # preparing data\n",
    "        train_data = Pool(X_train, label = y_train)\n",
    "        val_data = Pool(X_test, label = y_test)\n",
    "\n",
    "        model_cat = CatBoostClassifier(iterations=4500, learning_rate=0.01, depth=6, verbose = False, #plot = True,\n",
    "                                   l2_leaf_reg=14, rsm=1.0, loss_function='Logloss', border_count=128, thread_count=3,\n",
    "                                   use_best_model=True, ctr_border_count=16, bagging_temperature=0.8,\n",
    "                                   max_ctr_complexity=4, has_time=False, class_weights=None, eval_metric='AUC',\n",
    "                                   random_seed = 200+i\n",
    "                                  )\n",
    "        model_cat.fit(train_data, eval_set = val_data, use_best_model = True)\n",
    "\n",
    "        preds_valid = model_cat.predict_proba(Pool(X_test))[:, 1]\n",
    "        preds_tr_cat[test_index] += preds_valid\n",
    "        cv_scores.append(gini_normalized(y_test, preds_valid))\n",
    "        preds_cat += model_cat.predict_proba(Pool(df_test[features]))[:, 1] / cv_splits\n",
    "        print('Score: {:0.4f}'.format(cv_scores[-1]))\n",
    "\n",
    "    print('CV Score: {:0.4f} +- {:0.4f}'.format(np.mean(cv_scores), np.std(cv_scores)))\n",
    "    \n",
    "    df_preds_cat = pd.read_csv('Predictions/Base/cat/test.csv')\n",
    "    df_preds_cat[str(i)] = preds_cat\n",
    "    df_preds_cat.to_csv('Predictions/Base/cat/test.csv', index = False)\n",
    "    \n",
    "    df_preds_train_cat = pd.read_csv('Predictions/Base/cat/train.csv')\n",
    "    df_preds_train_cat[str(i)] = preds_tr_cat\n",
    "    df_preds_train_cat.to_csv('Predictions/Base/cat/train.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Greedy Forest\n",
    "rgf_python doesn't support multithreading so multiprocessing is used to run multiple models parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.2624, seed: 20\n",
      "Score: 0.2706, seed: 22\n",
      "Score: 0.2813, seed: 20\n",
      "Score: 0.2768, seed: 22\n",
      "Score: 0.3037, seed: 20\n",
      "Score: 0.2765, seed: 22\n",
      "Score: 0.2874, seed: 20\n",
      "Score: 0.2543, seed: 22\n",
      "Score: 0.2740, seed: 20\n",
      "Score: 0.3129, seed: 22\n",
      "Score: 0.2822, seed: 20\n",
      "Score: 0.2981, seed: 22\n",
      "Score: 0.2824, seed: 20\n",
      "Score: 0.2990, seed: 22\n",
      "Score: 0.2904, seed: 20\n",
      "Score: 0.2591, seed: 22\n",
      "Score: 0.2945, seed: 20\n",
      "Score: 0.2725, seed: 20\n",
      "CV Score: 0.2831 +- 0.0112, seed: 20\n",
      "Score: 0.2877, seed: 22\n",
      "Score: 0.2882, seed: 22\n",
      "CV Score: 0.2823 +- 0.0175, seed: 22\n"
     ]
    }
   ],
   "source": [
    "# Regularized Greedy Forest\n",
    "from rgf.sklearn import RGFClassifier     # https://github.com/fukatani/rgf_python\n",
    "import multiprocessing\n",
    "\n",
    "cv_splits = 10 #5 for first 10\n",
    "\n",
    "if False: # only for first use\n",
    "    df_preds_rgf = pd.DataFrame(df_test.copy()['id'])\n",
    "    df_preds_rgf.to_csv('Predictions/Base/rgf/test.csv', index = False)\n",
    "    df_preds_train_rgf = pd.DataFrame(df_train.copy()['id'])\n",
    "    df_preds_train_rgf.to_csv('Predictions/Base/rgf/train.csv', index = False)\n",
    "\n",
    "def run_rgf_worker(seed):\n",
    "    kf = StratifiedKFold(n_splits = cv_splits, shuffle = True, random_state = 300+seed)\n",
    "    \n",
    "    preds_rgf = np.zeros(len(df_test))\n",
    "    preds_tr_rgf = np.zeros(len(df_train))\n",
    "    \n",
    "    cv_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(df_train[features], df_train[label].values.ravel()):\n",
    "        X_train = df_train.iloc[train_index, :].loc[:, features]\n",
    "        y_train = df_train.iloc[train_index, :][label].values.ravel()\n",
    "        X_test = df_train.iloc[test_index, :].loc[:, features]\n",
    "        y_test = df_train.iloc[test_index, :][label].values.ravel()\n",
    "\n",
    "        model_rgf = RGFClassifier(max_leaf=10000, algorithm=\"RGF_Opt\", test_interval=100,\n",
    "                                  verbose=False, l2 = 0.01, sl2 = 0.0001, min_samples_leaf = 1,\n",
    "                                  learning_rate = 0.2)\n",
    "        model_rgf.fit(X_train, y_train)\n",
    "\n",
    "        preds_valid = model_rgf.predict_proba(X_test)[:, 1]\n",
    "        preds_tr_rgf[test_index] += preds_valid\n",
    "        cv_scores.append(gini_normalized(y_test, preds_valid))\n",
    "        preds_rgf += model_rgf.predict_proba(df_test[features])[:, 1] / cv_splits\n",
    "        print('Score: {:0.4f}, seed: {}'.format(cv_scores[-1], seed))\n",
    "        \n",
    "    print('CV Score: {:0.4f} +- {:0.4f}, seed: {}'.format(np.mean(cv_scores), np.std(cv_scores), seed))\n",
    "        \n",
    "    df_preds_rgf = pd.read_csv('Predictions/Base/rgf/test.csv')\n",
    "    df_preds_rgf[str(seed)] = preds_rgf\n",
    "    df_preds_rgf.to_csv('Predictions/Base/rgf/test.csv', index = False)\n",
    "\n",
    "    df_preds_train_rgf = pd.read_csv('Predictions/Base/rgf/train.csv')\n",
    "    df_preds_train_rgf[str(seed)] = preds_tr_rgf\n",
    "    df_preds_train_rgf.to_csv('Predictions/Base/rgf/train.csv', index = False)\n",
    "    \n",
    "for i in range(10, 12):\n",
    "    if __name__ == '__main__':\n",
    "        worker_rgf = multiprocessing.Process(target = run_rgf_worker, args = (i*2))\n",
    "        worker_rgf.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External kernels\n",
    "External kernels are added for ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forza Baseline\n",
    "https://www.kaggle.com/the1owl/forza-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pepe/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/Pepe/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/Pepe/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Shape:  (595212, 59)\n",
      "After Shape:  (595212, 186)\n",
      "Init Shape:  (892816, 58)\n",
      "After Shape:  (892816, 185)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from multiprocessing import *\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "col = [c for c in train.columns if c not in ['id','target']]\n",
    "col = [c for c in col if not c.startswith('ps_calc_')]\n",
    "\n",
    "train = train.replace(-1, np.NaN)\n",
    "d_median = train.median(axis=0)\n",
    "d_mean = train.mean(axis=0)\n",
    "train = train.fillna(-1)\n",
    "one_hot = {c: list(train[c].unique()) for c in train.columns if c not in ['id','target']}\n",
    "\n",
    "def transform_df(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "    for c in dcol:\n",
    "        if '_bin' not in c: #standard arithmetic\n",
    "            df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n",
    "            df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n",
    "            #df[c+str('_sq')] = np.power(df[c].values,2).astype(np.float32)\n",
    "            #df[c+str('_sqr')] = np.square(df[c].values).astype(np.float32)\n",
    "            #df[c+str('_log')] = np.log(np.abs(df[c].values) + 1)\n",
    "            #df[c+str('_exp')] = np.exp(df[c].values) - 1\n",
    "    for c in one_hot:\n",
    "        if len(one_hot[c])>2 and len(one_hot[c]) < 7:\n",
    "            for val in one_hot[c]:\n",
    "                df[c+'_oh_' + str(val)] = (df[c].values == val).astype(np.int)\n",
    "    return df\n",
    "\n",
    "def multi_transform(df):\n",
    "    print('Init Shape: ', df.shape)\n",
    "    p = Pool(cpu_count())\n",
    "    df = p.map(transform_df, np.array_split(df, cpu_count()))\n",
    "    df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "    p.close(); p.join()\n",
    "    print('After Shape: ', df.shape)\n",
    "    return df\n",
    "\n",
    "def gini(y, pred):\n",
    "    fpr, tpr, thr = metrics.roc_curve(y, pred, pos_label=1)\n",
    "    g = 2 * metrics.auc(fpr, tpr) -1\n",
    "    return g\n",
    "\n",
    "train = multi_transform(train)\n",
    "test = multi_transform(test)\n",
    "\n",
    "col = [c for c in train.columns if c not in ['id','target']]\n",
    "col = [c for c in col if not c.startswith('ps_calc_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.2835\n",
      "Score: 0.2887\n",
      "Score: 0.2941\n",
      "Score: 0.2689\n",
      "Score: 0.2759\n",
      "CV Score: 0.2822 +- 0.0090\n",
      "Score: 0.2759\n",
      "Score: 0.2868\n",
      "Score: 0.3008\n",
      "Score: 0.2853\n",
      "Score: 0.2620\n",
      "CV Score: 0.2822 +- 0.0128\n",
      "Score: 0.2809\n",
      "Score: 0.2860\n",
      "Score: 0.2800\n",
      "Score: 0.2846\n",
      "Score: 0.2866\n",
      "CV Score: 0.2836 +- 0.0027\n"
     ]
    }
   ],
   "source": [
    "#LightGBM\n",
    "def gini_lgb(preds, dtrain):\n",
    "    y = list(dtrain.get_label())\n",
    "    score = gini(y, preds) / gini(y, y)\n",
    "    return 'gini', score, True\n",
    "\n",
    "cv_splits = 5\n",
    "\n",
    "if False:\n",
    "    df_preds_FB_lgb = pd.DataFrame(df_test.copy()['id'])\n",
    "    df_preds_FB_lgb.to_csv('Predictions/Base/FB_lgb/test.csv', index = False)\n",
    "    df_preds_train_FB_lgb = pd.DataFrame(df_train.copy()['id'])\n",
    "    df_preds_train_FB_lgb.to_csv('Predictions/Base/FB_lgb/train.csv', index = False)\n",
    "\n",
    "for i in range(1, 4):\n",
    "    preds_FB_lgb = np.zeros(len(df_test))\n",
    "    preds_tr_FB_lgb = np.zeros(len(df_train))\n",
    "\n",
    "    kf = StratifiedKFold(n_splits = cv_splits, shuffle = True, random_state = 400+i)\n",
    "    cv_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(train[col], train[label].values.ravel()):\n",
    "        X_train = train.iloc[train_index, :].loc[:, col]\n",
    "        y_train = train.iloc[train_index, :][label].values.ravel()\n",
    "        X_test = train.iloc[test_index, :].loc[:, col]\n",
    "        y_test = train.iloc[test_index, :][label].values.ravel()\n",
    "\n",
    "        params = {'learning_rate': 0.002, 'max_depth': 4, 'boosting': 'gbdt', 'objective': 'binary', 'metric': 'auc', \n",
    "                  'is_training_metric': False, 'seed': i}\n",
    "        model2 = lgb.train(params, lgb.Dataset(X_train, label=y_train), 10000, lgb.Dataset(X_test, label=y_test), \n",
    "                           verbose_eval=None, feval=gini_lgb, early_stopping_rounds=250)\n",
    "\n",
    "        preds_valid = model2.predict(X_test)\n",
    "        preds_tr_FB_lgb[test_index] += preds_valid\n",
    "        cv_scores.append(gini_normalized(y_test, preds_valid))\n",
    "        preds_FB_lgb += model2.predict(test[col]) / cv_splits\n",
    "        print('Score: {:0.4f}'.format(cv_scores[-1]))\n",
    "\n",
    "    print('CV Score: {:0.4f} +- {:0.4f}'.format(np.mean(cv_scores), np.std(cv_scores)))\n",
    "    df_preds_FB_lgb = pd.read_csv('Predictions/Base/FB_lgb/test.csv')\n",
    "    df_preds_FB_lgb[str(i)] = preds_FB_lgb\n",
    "    df_preds_FB_lgb.to_csv('Predictions/Base/FB_lgb/test.csv', index = False)\n",
    "\n",
    "    df_preds_train_FB_lgb = pd.read_csv('Predictions/Base/FB_lgb/train.csv')\n",
    "    df_preds_train_FB_lgb[str(i)] = preds_tr_FB_lgb\n",
    "    df_preds_train_FB_lgb.to_csv('Predictions/Base/FB_lgb/train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3242\n",
      "Score: 0.2916\n",
      "Score: 0.2634\n",
      "Score: 0.2931\n",
      "Score: 0.2807\n",
      "Score: 0.2871\n",
      "Score: 0.2731\n",
      "Score: 0.2910\n",
      "Score: 0.2913\n",
      "Score: 0.2656\n",
      "CV Score: 0.2861 +- 0.0165\n",
      "Score: 0.2841\n",
      "Score: 0.2981\n",
      "Score: 0.2899\n",
      "Score: 0.2920\n",
      "Score: 0.2960\n",
      "Score: 0.2914\n",
      "Score: 0.2688\n",
      "Score: 0.2931\n",
      "Score: 0.2822\n",
      "Score: 0.2694\n",
      "CV Score: 0.2865 +- 0.0098\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "def gini_xgb(pred, y):\n",
    "    y = y.get_label()\n",
    "    return 'gini', gini(y, pred)\n",
    "\n",
    "cv_splits = 10 #5 for first 4\n",
    "\n",
    "\n",
    "if False:\n",
    "    df_preds_FB_xgb = pd.DataFrame(df_test.copy()['id'])\n",
    "    df_preds_FB_xgb.to_csv('Predictions/Base/FB_xgb/test.csv', index = False)\n",
    "    df_preds_train_FB_xgb = pd.DataFrame(df_train.copy()['id'])\n",
    "    df_preds_train_FB_xgb.to_csv('Predictions/Base/FB_xgb/train.csv', index = False)\n",
    "\n",
    "for i in range(5, 7):\n",
    "    preds_FB_xgb = np.zeros(len(df_test))\n",
    "    preds_tr_FB_xgb = np.zeros(len(df_train))\n",
    "\n",
    "    kf = StratifiedKFold(n_splits = cv_splits, shuffle = True, random_state = 500+i)\n",
    "    cv_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(train[col], train[label].values.ravel()):\n",
    "\n",
    "        X_train = train.iloc[train_index, :].loc[:, col]\n",
    "        y_train = train.iloc[train_index, :][label].values.ravel()\n",
    "        X_test = train.iloc[test_index, :].loc[:, col]\n",
    "        y_test = train.iloc[test_index, :][label].values.ravel()\n",
    "\n",
    "        params = {'eta': 0.01, #0.005, for first 4 \n",
    "                  'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', \n",
    "                  'eval_metric': 'auc', 'seed': i, 'silent': True}\n",
    "        watchlist = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_test, y_test), 'valid')]\n",
    "        model1 = xgb.train(params, xgb.DMatrix(X_train, y_train), 20000,  watchlist, feval=gini_xgb, maximize=True, \n",
    "                           verbose_eval=None, early_stopping_rounds=200)\n",
    "\n",
    "        preds_valid = model1.predict(xgb.DMatrix(X_test))\n",
    "        preds_tr_FB_xgb[test_index] += preds_valid\n",
    "        cv_scores.append(gini_normalized(y_test, preds_valid))\n",
    "        preds_FB_xgb += model1.predict(xgb.DMatrix(test[col])) / cv_splits\n",
    "        print('Score: {:0.4f}'.format(cv_scores[-1]))\n",
    "\n",
    "    print('CV Score: {:0.4f} +- {:0.4f}'.format(np.mean(cv_scores), np.std(cv_scores)))\n",
    "    \n",
    "    df_preds_FB_xgb = pd.read_csv('Predictions/Base/FB_xgb/test.csv')\n",
    "    df_preds_FB_xgb[str(i)] = preds_FB_xgb\n",
    "    df_preds_FB_xgb.to_csv('Predictions/Base/FB_xgb/test.csv', index = False)\n",
    "\n",
    "    df_preds_train_FB_xgb = pd.read_csv('Predictions/Base/FB_xgb/train.csv')\n",
    "    df_preds_train_FB_xgb[str(i)] = preds_tr_FB_xgb\n",
    "    df_preds_train_FB_xgb.to_csv('Predictions/Base/FB_xgb/train.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "https://www.kaggle.com/tilii7/keras-averaging-runs-gini-early-stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import load_model, Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, Callback\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class roc_auc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict_proba(self.x, verbose=0)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        logs['roc_auc'] = roc_auc_score(self.y, y_pred)\n",
    "        logs['norm_gini'] = ( roc_auc_score(self.y, y_pred) * 2 ) - 1\n",
    "\n",
    "        y_pred_val = self.model.predict_proba(self.x_val, verbose=0)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        logs['roc_auc_val'] = roc_auc_score(self.y_val, y_pred_val)\n",
    "        logs['norm_gini_val'] = ( roc_auc_score(self.y_val, y_pred_val) * 2 ) - 1\n",
    "\n",
    "        print('\\rroc_auc: %s - roc_auc_val: %s - norm_gini: %s - norm_gini_val: %s' % (str(round(roc,5)),str(round(roc_val,5)),str(round((roc*2-1),5)),str(round((roc_val*2-1),5))), end=10*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod(\n",
    "            (datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' %\n",
    "              (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "def scale_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train and test data path\n",
    "DATA_TRAIN_PATH = 'train.csv'\n",
    "DATA_TEST_PATH = 'test.csv'\n",
    "\n",
    "def load_data(path_train=DATA_TRAIN_PATH, path_test=DATA_TEST_PATH):\n",
    "    train_loader = pd.read_csv(path_train, dtype={'target': np.int8, 'id': np.int32})\n",
    "    train = train_loader.drop(['target', 'id'], axis=1)\n",
    "    train_labels = train_loader['target'].values\n",
    "    train_ids = train_loader['id'].values\n",
    "    print('\\n Shape of raw train data:', train.shape)\n",
    "\n",
    "    test_loader = pd.read_csv(path_test, dtype={'id': np.int32})\n",
    "    test = test_loader.drop(['id'], axis=1)\n",
    "    test_ids = test_loader['id'].values\n",
    "    print(' Shape of raw test data:', test.shape)\n",
    "\n",
    "    return train, train_labels, test, train_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Shape of raw train data: (595212, 57)\n",
      " Shape of raw test data: (892816, 57)\n",
      "\n",
      " Shape of processed train data: (595212, 227)\n",
      " Shape of processed test data: (892816, 227)\n"
     ]
    }
   ],
   "source": [
    "# Load data set and target values\n",
    "train, target, test, tr_ids, te_ids = load_data()\n",
    "n_train = train.shape[0]\n",
    "train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "col_to_drop = train.columns[train.columns.str.endswith('_cat')]\n",
    "col_to_dummify = train.columns[train.columns.str.endswith('_cat')].astype(str).tolist()\n",
    "\n",
    "for col in col_to_dummify:\n",
    "    dummy = pd.get_dummies(train_test[col].astype('category'))\n",
    "    columns = dummy.columns.astype(str).tolist()\n",
    "    columns = [col + '_' + w for w in columns]\n",
    "    dummy.columns = columns\n",
    "    train_test = pd.concat((train_test, dummy), axis=1)\n",
    "\n",
    "train_test.drop(col_to_dummify, axis=1, inplace=True)\n",
    "train_test_scaled, scaler = scale_data(train_test)\n",
    "train = train_test_scaled[:n_train, :]\n",
    "test = train_test_scaled[n_train:, :]\n",
    "print('\\n Shape of processed train data:', train.shape)\n",
    "print(' Shape of processed test data:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patience = 10\n",
    "batchsize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 476169 samples, validate on 119043 samples\n",
      "Epoch 1/100\n",
      "roc_auc: 0.61754 - roc_auc_val: 0.61333 - norm_gini: 0.23508 - norm_gini_val: 0.22665          \n",
      "Epoch 00001: norm_gini_val improved from -inf to 0.22665, saving model to keras/keras-5fold-run-01-v1-fold-01-run-07.check\n",
      " - 141s - loss: 0.1826 - acc: 0.9532 - val_loss: 0.1537 - val_acc: 0.9636\n",
      "Epoch 2/100\n",
      "roc_auc: 0.63281 - roc_auc_val: 0.6249 - norm_gini: 0.26561 - norm_gini_val: 0.24979          \n",
      "Epoch 00002: norm_gini_val improved from 0.22665 to 0.24979, saving model to keras/keras-5fold-run-01-v1-fold-01-run-07.check\n",
      " - 126s - loss: 0.1548 - acc: 0.9636 - val_loss: 0.1529 - val_acc: 0.9636\n",
      "Epoch 3/100\n",
      "roc_auc: 0.63524 - roc_auc_val: 0.62809 - norm_gini: 0.27048 - norm_gini_val: 0.25619          \n",
      "Epoch 00003: norm_gini_val improved from 0.24979 to 0.25619, saving model to keras/keras-5fold-run-01-v1-fold-01-run-07.check\n",
      " - 127s - loss: 0.1538 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9636\n",
      "Epoch 4/100\n",
      "roc_auc: 0.6384 - roc_auc_val: 0.62897 - norm_gini: 0.2768 - norm_gini_val: 0.25795          \n",
      "Epoch 00004: norm_gini_val improved from 0.25619 to 0.25795, saving model to keras/keras-5fold-run-01-v1-fold-01-run-07.check\n",
      " - 125s - loss: 0.1536 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9636\n",
      "Epoch 5/100\n",
      "roc_auc: 0.63961 - roc_auc_val: 0.63116 - norm_gini: 0.27923 - norm_gini_val: 0.26232          \n",
      "Epoch 00005: norm_gini_val improved from 0.25795 to 0.26232, saving model to keras/keras-5fold-run-01-v1-fold-01-run-07.check\n",
      " - 125s - loss: 0.1532 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 6/100\n",
      "roc_auc: 0.64166 - roc_auc_val: 0.6322 - norm_gini: 0.28332 - norm_gini_val: 0.26439          \n",
      "Epoch 00006: norm_gini_val improved from 0.26232 to 0.26439, saving model to keras/keras-5fold-run-01-v1-fold-01-run-07.check\n",
      " - 127s - loss: 0.1530 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 7/100\n",
      "roc_auc: 0.64187 - roc_auc_val: 0.63125 - norm_gini: 0.28373 - norm_gini_val: 0.26249          \n",
      "Epoch 00007: norm_gini_val did not improve\n",
      " - 125s - loss: 0.1529 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 8/100\n",
      "roc_auc: 0.64538 - roc_auc_val: 0.63358 - norm_gini: 0.29076 - norm_gini_val: 0.26717          \n",
      "Epoch 00008: norm_gini_val improved from 0.26439 to 0.26717, saving model to keras/keras-5fold-run-01-v1-fold-01-run-07.check\n",
      " - 124s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 9/100\n",
      "roc_auc: 0.64568 - roc_auc_val: 0.63156 - norm_gini: 0.29135 - norm_gini_val: 0.26312          \n",
      "Epoch 00009: norm_gini_val did not improve\n",
      " - 124s - loss: 0.1527 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 10/100\n",
      "roc_auc: 0.64707 - roc_auc_val: 0.63279 - norm_gini: 0.29415 - norm_gini_val: 0.26558          \n",
      "Epoch 00010: norm_gini_val did not improve\n",
      " - 126s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 11/100\n",
      "roc_auc: 0.6489 - roc_auc_val: 0.63392 - norm_gini: 0.2978 - norm_gini_val: 0.26784          \n",
      "Epoch 00011: norm_gini_val improved from 0.26717 to 0.26784, saving model to keras/keras-5fold-run-01-v1-fold-01-run-07.check\n",
      " - 124s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 12/100\n",
      "roc_auc: 0.64966 - roc_auc_val: 0.63374 - norm_gini: 0.29932 - norm_gini_val: 0.26749          \n",
      "Epoch 00012: norm_gini_val did not improve\n",
      " - 126s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 13/100\n",
      "roc_auc: 0.65089 - roc_auc_val: 0.63487 - norm_gini: 0.30179 - norm_gini_val: 0.26974          \n",
      "Epoch 00013: norm_gini_val improved from 0.26784 to 0.26974, saving model to keras/keras-5fold-run-01-v1-fold-01-run-07.check\n",
      " - 126s - loss: 0.1523 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 14/100\n",
      "roc_auc: 0.65162 - roc_auc_val: 0.63581 - norm_gini: 0.30323 - norm_gini_val: 0.27162          \n",
      "Epoch 00014: norm_gini_val improved from 0.26974 to 0.27162, saving model to keras/keras-5fold-run-01-v1-fold-01-run-07.check\n",
      " - 126s - loss: 0.1523 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 15/100\n",
      "roc_auc: 0.65203 - roc_auc_val: 0.63496 - norm_gini: 0.30407 - norm_gini_val: 0.26992          \n",
      "Epoch 00015: norm_gini_val did not improve\n",
      " - 126s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9636\n",
      "Epoch 16/100\n",
      "roc_auc: 0.65309 - roc_auc_val: 0.63469 - norm_gini: 0.30619 - norm_gini_val: 0.26939          \n",
      "Epoch 00016: norm_gini_val did not improve\n",
      " - 125s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 17/100\n",
      "roc_auc: 0.65481 - roc_auc_val: 0.63456 - norm_gini: 0.30962 - norm_gini_val: 0.26912          \n",
      "Epoch 00017: norm_gini_val did not improve\n",
      " - 126s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 18/100\n",
      "roc_auc: 0.65486 - roc_auc_val: 0.63411 - norm_gini: 0.30972 - norm_gini_val: 0.26821          \n",
      "Epoch 00018: norm_gini_val did not improve\n",
      " - 126s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 19/100\n",
      "roc_auc: 0.65481 - roc_auc_val: 0.63533 - norm_gini: 0.30961 - norm_gini_val: 0.27066          \n",
      "Epoch 00019: norm_gini_val did not improve\n",
      " - 125s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 20/100\n",
      "roc_auc: 0.65677 - roc_auc_val: 0.63593 - norm_gini: 0.31354 - norm_gini_val: 0.27185          \n",
      "Epoch 00020: norm_gini_val improved from 0.27162 to 0.27185, saving model to keras/keras-5fold-run-01-v1-fold-01-run-07.check\n",
      " - 124s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 21/100\n",
      "roc_auc: 0.65769 - roc_auc_val: 0.63588 - norm_gini: 0.31539 - norm_gini_val: 0.27176          \n",
      "Epoch 00021: norm_gini_val did not improve\n",
      " - 101s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 22/100\n",
      "roc_auc: 0.65824 - roc_auc_val: 0.63519 - norm_gini: 0.31649 - norm_gini_val: 0.27038          \n",
      "Epoch 00022: norm_gini_val did not improve\n",
      " - 97s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9636\n",
      "Epoch 23/100\n",
      "roc_auc: 0.65842 - roc_auc_val: 0.63501 - norm_gini: 0.31684 - norm_gini_val: 0.27002          \n",
      "Epoch 00023: norm_gini_val did not improve\n",
      " - 96s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9635\n",
      "Epoch 24/100\n",
      "roc_auc: 0.65918 - roc_auc_val: 0.63654 - norm_gini: 0.31836 - norm_gini_val: 0.27307          \n",
      "Epoch 00024: norm_gini_val improved from 0.27185 to 0.27307, saving model to keras/keras-5fold-run-01-v1-fold-01-run-07.check\n",
      " - 123s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9636\n",
      "Epoch 25/100\n",
      "roc_auc: 0.65983 - roc_auc_val: 0.63561 - norm_gini: 0.31965 - norm_gini_val: 0.27122          \n",
      "Epoch 00025: norm_gini_val did not improve\n",
      " - 125s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 26/100\n",
      "roc_auc: 0.66029 - roc_auc_val: 0.63474 - norm_gini: 0.32057 - norm_gini_val: 0.26948          \n",
      "Epoch 00026: norm_gini_val did not improve\n",
      " - 126s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 27/100\n",
      "roc_auc: 0.65875 - roc_auc_val: 0.63343 - norm_gini: 0.31751 - norm_gini_val: 0.26686          \n",
      "Epoch 00027: norm_gini_val did not improve\n",
      " - 125s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 28/100\n",
      "roc_auc: 0.6619 - roc_auc_val: 0.63467 - norm_gini: 0.32381 - norm_gini_val: 0.26934          \n",
      "Epoch 00028: norm_gini_val did not improve\n",
      " - 125s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 29/100\n",
      "roc_auc: 0.66125 - roc_auc_val: 0.63521 - norm_gini: 0.3225 - norm_gini_val: 0.27043          \n",
      "Epoch 00029: norm_gini_val did not improve\n",
      " - 125s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 30/100\n",
      "roc_auc: 0.66302 - roc_auc_val: 0.63318 - norm_gini: 0.32604 - norm_gini_val: 0.26636          \n",
      "Epoch 00030: norm_gini_val did not improve\n",
      " - 125s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 31/100\n",
      "roc_auc: 0.663 - roc_auc_val: 0.63465 - norm_gini: 0.32601 - norm_gini_val: 0.2693          \n",
      "Epoch 00031: norm_gini_val did not improve\n",
      " - 126s - loss: 0.1515 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 32/100\n",
      "roc_auc: 0.66277 - roc_auc_val: 0.63516 - norm_gini: 0.32554 - norm_gini_val: 0.27032          \n",
      "Epoch 00032: norm_gini_val did not improve\n",
      " - 126s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "roc_auc: 0.66199 - roc_auc_val: 0.63491 - norm_gini: 0.32398 - norm_gini_val: 0.26983          \n",
      "Epoch 00033: norm_gini_val did not improve\n",
      " - 125s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 34/100\n",
      "roc_auc: 0.66427 - roc_auc_val: 0.63478 - norm_gini: 0.32855 - norm_gini_val: 0.26956          \n",
      "Epoch 00034: norm_gini_val did not improve\n",
      " - 125s - loss: 0.1516 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 00034: early stopping\n",
      "Run 6, Fold 0, Score: 0.2731\n",
      "Train on 476169 samples, validate on 119043 samples\n",
      "Epoch 1/100\n",
      "roc_auc: 0.62779 - roc_auc_val: 0.61938 - norm_gini: 0.25557 - norm_gini_val: 0.23876          \n",
      "Epoch 00001: norm_gini_val improved from -inf to 0.23876, saving model to keras/keras-5fold-run-01-v1-fold-02-run-07.check\n",
      " - 153s - loss: 0.1820 - acc: 0.9535 - val_loss: 0.1533 - val_acc: 0.9636\n",
      "Epoch 2/100\n",
      "roc_auc: 0.6323 - roc_auc_val: 0.62532 - norm_gini: 0.26461 - norm_gini_val: 0.25065          \n",
      "Epoch 00002: norm_gini_val improved from 0.23876 to 0.25065, saving model to keras/keras-5fold-run-01-v1-fold-02-run-07.check\n",
      " - 127s - loss: 0.1548 - acc: 0.9636 - val_loss: 0.1530 - val_acc: 0.9636\n",
      "Epoch 3/100\n",
      "roc_auc: 0.63723 - roc_auc_val: 0.62681 - norm_gini: 0.27445 - norm_gini_val: 0.25361          \n",
      "Epoch 00003: norm_gini_val improved from 0.25065 to 0.25361, saving model to keras/keras-5fold-run-01-v1-fold-02-run-07.check\n",
      " - 128s - loss: 0.1539 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9636\n",
      "Epoch 4/100\n",
      "roc_auc: 0.63946 - roc_auc_val: 0.62794 - norm_gini: 0.27893 - norm_gini_val: 0.25588          \n",
      "Epoch 00004: norm_gini_val improved from 0.25361 to 0.25588, saving model to keras/keras-5fold-run-01-v1-fold-02-run-07.check\n",
      " - 128s - loss: 0.1535 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9636\n",
      "Epoch 5/100\n",
      "roc_auc: 0.64056 - roc_auc_val: 0.62898 - norm_gini: 0.28113 - norm_gini_val: 0.25796          \n",
      "Epoch 00005: norm_gini_val improved from 0.25588 to 0.25796, saving model to keras/keras-5fold-run-01-v1-fold-02-run-07.check\n",
      " - 129s - loss: 0.1532 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9636\n",
      "Epoch 6/100\n",
      "roc_auc: 0.64171 - roc_auc_val: 0.62918 - norm_gini: 0.28342 - norm_gini_val: 0.25837          \n",
      "Epoch 00006: norm_gini_val improved from 0.25796 to 0.25837, saving model to keras/keras-5fold-run-01-v1-fold-02-run-07.check\n",
      " - 129s - loss: 0.1531 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9636\n",
      "Epoch 7/100\n",
      "roc_auc: 0.64345 - roc_auc_val: 0.62854 - norm_gini: 0.28691 - norm_gini_val: 0.25708          \n",
      "Epoch 00007: norm_gini_val did not improve\n",
      " - 127s - loss: 0.1529 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9636\n",
      "Epoch 8/100\n",
      "roc_auc: 0.64425 - roc_auc_val: 0.63091 - norm_gini: 0.28851 - norm_gini_val: 0.26182          \n",
      "Epoch 00008: norm_gini_val improved from 0.25837 to 0.26182, saving model to keras/keras-5fold-run-01-v1-fold-02-run-07.check\n",
      " - 127s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 9/100\n",
      "roc_auc: 0.64615 - roc_auc_val: 0.62705 - norm_gini: 0.2923 - norm_gini_val: 0.2541          \n",
      "Epoch 00009: norm_gini_val did not improve\n",
      " - 127s - loss: 0.1525 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9636\n",
      "Epoch 10/100\n",
      "roc_auc: 0.64754 - roc_auc_val: 0.62711 - norm_gini: 0.29508 - norm_gini_val: 0.25421          \n",
      "Epoch 00010: norm_gini_val did not improve\n",
      " - 128s - loss: 0.1526 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9635\n",
      "Epoch 11/100\n",
      "roc_auc: 0.64877 - roc_auc_val: 0.62914 - norm_gini: 0.29755 - norm_gini_val: 0.25828          \n",
      "Epoch 00011: norm_gini_val did not improve\n",
      " - 129s - loss: 0.1525 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 12/100\n",
      "roc_auc: 0.65016 - roc_auc_val: 0.63138 - norm_gini: 0.30033 - norm_gini_val: 0.26277          \n",
      "Epoch 00012: norm_gini_val improved from 0.26182 to 0.26277, saving model to keras/keras-5fold-run-01-v1-fold-02-run-07.check\n",
      " - 130s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 13/100\n",
      "roc_auc: 0.65124 - roc_auc_val: 0.62957 - norm_gini: 0.30248 - norm_gini_val: 0.25913          \n",
      "Epoch 00013: norm_gini_val did not improve\n",
      " - 128s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 14/100\n",
      "roc_auc: 0.65098 - roc_auc_val: 0.63061 - norm_gini: 0.30197 - norm_gini_val: 0.26122          \n",
      "Epoch 00014: norm_gini_val did not improve\n",
      " - 129s - loss: 0.1523 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9636\n",
      "Epoch 15/100\n",
      "roc_auc: 0.65291 - roc_auc_val: 0.62789 - norm_gini: 0.30582 - norm_gini_val: 0.25579          \n",
      "Epoch 00015: norm_gini_val did not improve\n",
      " - 132s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9636\n",
      "Epoch 16/100\n",
      "roc_auc: 0.64966 - roc_auc_val: 0.62957 - norm_gini: 0.29932 - norm_gini_val: 0.25915          \n",
      "Epoch 00016: norm_gini_val did not improve\n",
      " - 128s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 17/100\n",
      "roc_auc: 0.65266 - roc_auc_val: 0.62878 - norm_gini: 0.30532 - norm_gini_val: 0.25755          \n",
      "Epoch 00017: norm_gini_val did not improve\n",
      " - 129s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9636\n",
      "Epoch 18/100\n",
      "roc_auc: 0.65458 - roc_auc_val: 0.62934 - norm_gini: 0.30916 - norm_gini_val: 0.25868          \n",
      "Epoch 00018: norm_gini_val did not improve\n",
      " - 129s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9636\n",
      "Epoch 19/100\n",
      "roc_auc: 0.65546 - roc_auc_val: 0.62978 - norm_gini: 0.31092 - norm_gini_val: 0.25955          \n",
      "Epoch 00019: norm_gini_val did not improve\n",
      " - 129s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 20/100\n",
      "roc_auc: 0.65682 - roc_auc_val: 0.6303 - norm_gini: 0.31364 - norm_gini_val: 0.26061          \n",
      "Epoch 00020: norm_gini_val did not improve\n",
      " - 128s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 21/100\n",
      "roc_auc: 0.65696 - roc_auc_val: 0.6309 - norm_gini: 0.31393 - norm_gini_val: 0.2618          \n",
      "Epoch 00021: norm_gini_val did not improve\n",
      " - 129s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 22/100\n",
      "roc_auc: 0.65844 - roc_auc_val: 0.63076 - norm_gini: 0.31688 - norm_gini_val: 0.26153          \n",
      "Epoch 00022: norm_gini_val did not improve\n",
      " - 128s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9635\n",
      "Epoch 00022: early stopping\n",
      "Run 6, Fold 1, Score: 0.2628\n",
      "Train on 476169 samples, validate on 119043 samples\n",
      "Epoch 1/100\n",
      "roc_auc: 0.62704 - roc_auc_val: 0.62364 - norm_gini: 0.25409 - norm_gini_val: 0.24727          \n",
      "Epoch 00001: norm_gini_val improved from -inf to 0.24727, saving model to keras/keras-5fold-run-01-v1-fold-03-run-07.check\n",
      " - 118s - loss: 0.1822 - acc: 0.9533 - val_loss: 0.1531 - val_acc: 0.9636\n",
      "Epoch 2/100\n",
      "roc_auc: 0.63207 - roc_auc_val: 0.62849 - norm_gini: 0.26413 - norm_gini_val: 0.25697          \n",
      "Epoch 00002: norm_gini_val improved from 0.24727 to 0.25697, saving model to keras/keras-5fold-run-01-v1-fold-03-run-07.check\n",
      " - 101s - loss: 0.1550 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 3/100\n",
      "roc_auc: 0.63577 - roc_auc_val: 0.63053 - norm_gini: 0.27154 - norm_gini_val: 0.26105          \n",
      "Epoch 00003: norm_gini_val improved from 0.25697 to 0.26105, saving model to keras/keras-5fold-run-01-v1-fold-03-run-07.check\n",
      " - 100s - loss: 0.1540 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 4/100\n",
      "roc_auc: 0.63876 - roc_auc_val: 0.63159 - norm_gini: 0.27751 - norm_gini_val: 0.26318          \n",
      "Epoch 00004: norm_gini_val improved from 0.26105 to 0.26318, saving model to keras/keras-5fold-run-01-v1-fold-03-run-07.check\n",
      " - 110s - loss: 0.1536 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 5/100\n",
      "roc_auc: 0.638 - roc_auc_val: 0.63188 - norm_gini: 0.27599 - norm_gini_val: 0.26376          \n",
      "Epoch 00005: norm_gini_val improved from 0.26318 to 0.26376, saving model to keras/keras-5fold-run-01-v1-fold-03-run-07.check\n",
      " - 126s - loss: 0.1533 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 6/100\n",
      "roc_auc: 0.64091 - roc_auc_val: 0.63342 - norm_gini: 0.28183 - norm_gini_val: 0.26685          \n",
      "Epoch 00006: norm_gini_val improved from 0.26376 to 0.26685, saving model to keras/keras-5fold-run-01-v1-fold-03-run-07.check\n",
      " - 131s - loss: 0.1532 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 7/100\n",
      "roc_auc: 0.64219 - roc_auc_val: 0.63248 - norm_gini: 0.28438 - norm_gini_val: 0.26496          \n",
      "Epoch 00007: norm_gini_val did not improve\n",
      " - 131s - loss: 0.1530 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "roc_auc: 0.64448 - roc_auc_val: 0.63288 - norm_gini: 0.28897 - norm_gini_val: 0.26576          \n",
      "Epoch 00008: norm_gini_val did not improve\n",
      " - 129s - loss: 0.1529 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 9/100\n",
      "roc_auc: 0.6452 - roc_auc_val: 0.63353 - norm_gini: 0.29039 - norm_gini_val: 0.26705          \n",
      "Epoch 00009: norm_gini_val improved from 0.26685 to 0.26705, saving model to keras/keras-5fold-run-01-v1-fold-03-run-07.check\n",
      " - 131s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 10/100\n",
      "roc_auc: 0.64707 - roc_auc_val: 0.63428 - norm_gini: 0.29414 - norm_gini_val: 0.26855          \n",
      "Epoch 00010: norm_gini_val improved from 0.26705 to 0.26855, saving model to keras/keras-5fold-run-01-v1-fold-03-run-07.check\n",
      " - 132s - loss: 0.1526 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 11/100\n",
      "roc_auc: 0.64758 - roc_auc_val: 0.63268 - norm_gini: 0.29516 - norm_gini_val: 0.26537          \n",
      "Epoch 00011: norm_gini_val did not improve\n",
      " - 132s - loss: 0.1525 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 12/100\n",
      "roc_auc: 0.6483 - roc_auc_val: 0.63476 - norm_gini: 0.29659 - norm_gini_val: 0.26952          \n",
      "Epoch 00012: norm_gini_val improved from 0.26855 to 0.26952, saving model to keras/keras-5fold-run-01-v1-fold-03-run-07.check\n",
      " - 133s - loss: 0.1526 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9636\n",
      "Epoch 13/100\n",
      "roc_auc: 0.65039 - roc_auc_val: 0.63441 - norm_gini: 0.30077 - norm_gini_val: 0.26881          \n",
      "Epoch 00013: norm_gini_val did not improve\n",
      " - 131s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 14/100\n",
      "roc_auc: 0.65076 - roc_auc_val: 0.63498 - norm_gini: 0.30151 - norm_gini_val: 0.26997          \n",
      "Epoch 00014: norm_gini_val improved from 0.26952 to 0.26997, saving model to keras/keras-5fold-run-01-v1-fold-03-run-07.check\n",
      " - 132s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9636\n",
      "Epoch 15/100\n",
      "roc_auc: 0.65233 - roc_auc_val: 0.63469 - norm_gini: 0.30465 - norm_gini_val: 0.26937          \n",
      "Epoch 00015: norm_gini_val did not improve\n",
      " - 131s - loss: 0.1523 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 16/100\n",
      "roc_auc: 0.65283 - roc_auc_val: 0.63535 - norm_gini: 0.30566 - norm_gini_val: 0.27069          \n",
      "Epoch 00016: norm_gini_val improved from 0.26997 to 0.27069, saving model to keras/keras-5fold-run-01-v1-fold-03-run-07.check\n",
      " - 133s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9636\n",
      "Epoch 17/100\n",
      "roc_auc: 0.65266 - roc_auc_val: 0.63579 - norm_gini: 0.30532 - norm_gini_val: 0.27159          \n",
      "Epoch 00017: norm_gini_val improved from 0.27069 to 0.27159, saving model to keras/keras-5fold-run-01-v1-fold-03-run-07.check\n",
      " - 131s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 18/100\n",
      "roc_auc: 0.65327 - roc_auc_val: 0.63484 - norm_gini: 0.30654 - norm_gini_val: 0.26968          \n",
      "Epoch 00018: norm_gini_val did not improve\n",
      " - 130s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 19/100\n",
      "roc_auc: 0.65395 - roc_auc_val: 0.63405 - norm_gini: 0.3079 - norm_gini_val: 0.2681          \n",
      "Epoch 00019: norm_gini_val did not improve\n",
      " - 131s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 20/100\n",
      "roc_auc: 0.65471 - roc_auc_val: 0.63542 - norm_gini: 0.30942 - norm_gini_val: 0.27084          \n",
      "Epoch 00020: norm_gini_val did not improve\n",
      " - 132s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 21/100\n",
      "roc_auc: 0.65552 - roc_auc_val: 0.635 - norm_gini: 0.31103 - norm_gini_val: 0.27          \n",
      "Epoch 00021: norm_gini_val did not improve\n",
      " - 133s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9636\n",
      "Epoch 22/100\n",
      "roc_auc: 0.65672 - roc_auc_val: 0.63455 - norm_gini: 0.31344 - norm_gini_val: 0.26911          \n",
      "Epoch 00022: norm_gini_val did not improve\n",
      " - 132s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9636\n",
      "Epoch 23/100\n",
      "roc_auc: 0.65682 - roc_auc_val: 0.63345 - norm_gini: 0.31363 - norm_gini_val: 0.26691          \n",
      "Epoch 00023: norm_gini_val did not improve\n",
      " - 133s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 24/100\n",
      "roc_auc: 0.65816 - roc_auc_val: 0.63388 - norm_gini: 0.31632 - norm_gini_val: 0.26776          \n",
      "Epoch 00024: norm_gini_val did not improve\n",
      " - 132s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 25/100\n",
      "roc_auc: 0.65914 - roc_auc_val: 0.63424 - norm_gini: 0.31828 - norm_gini_val: 0.26849          \n",
      "Epoch 00025: norm_gini_val did not improve\n",
      " - 132s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 26/100\n",
      "roc_auc: 0.65977 - roc_auc_val: 0.63376 - norm_gini: 0.31954 - norm_gini_val: 0.26752          \n",
      "Epoch 00026: norm_gini_val did not improve\n",
      " - 132s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 27/100\n",
      "roc_auc: 0.66033 - roc_auc_val: 0.63436 - norm_gini: 0.32065 - norm_gini_val: 0.26872          \n",
      "Epoch 00027: norm_gini_val did not improve\n",
      " - 111s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 00027: early stopping\n",
      "Run 6, Fold 2, Score: 0.2716\n",
      "Train on 476170 samples, validate on 119042 samples\n",
      "Epoch 1/100\n",
      "roc_auc: 0.62914 - roc_auc_val: 0.62362 - norm_gini: 0.25828 - norm_gini_val: 0.24723          \n",
      "Epoch 00001: norm_gini_val improved from -inf to 0.24723, saving model to keras/keras-5fold-run-01-v1-fold-04-run-07.check\n",
      " - 141s - loss: 0.1817 - acc: 0.9534 - val_loss: 0.1530 - val_acc: 0.9636\n",
      "Epoch 2/100\n",
      "roc_auc: 0.63392 - roc_auc_val: 0.62796 - norm_gini: 0.26784 - norm_gini_val: 0.25593          \n",
      "Epoch 00002: norm_gini_val improved from 0.24723 to 0.25593, saving model to keras/keras-5fold-run-01-v1-fold-04-run-07.check\n",
      " - 134s - loss: 0.1548 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9636\n",
      "Epoch 3/100\n",
      "roc_auc: 0.63586 - roc_auc_val: 0.62813 - norm_gini: 0.27171 - norm_gini_val: 0.25626          \n",
      "Epoch 00003: norm_gini_val improved from 0.25593 to 0.25626, saving model to keras/keras-5fold-run-01-v1-fold-04-run-07.check\n",
      " - 133s - loss: 0.1539 - acc: 0.9636 - val_loss: 0.1529 - val_acc: 0.9636\n",
      "Epoch 4/100\n",
      "roc_auc: 0.63684 - roc_auc_val: 0.62801 - norm_gini: 0.27368 - norm_gini_val: 0.25602          \n",
      "Epoch 00004: norm_gini_val did not improve\n",
      " - 133s - loss: 0.1536 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9636\n",
      "Epoch 5/100\n",
      "roc_auc: 0.64128 - roc_auc_val: 0.63158 - norm_gini: 0.28256 - norm_gini_val: 0.26316          \n",
      "Epoch 00005: norm_gini_val improved from 0.25626 to 0.26316, saving model to keras/keras-5fold-run-01-v1-fold-04-run-07.check\n",
      " - 135s - loss: 0.1532 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 6/100\n",
      "roc_auc: 0.64161 - roc_auc_val: 0.63199 - norm_gini: 0.28322 - norm_gini_val: 0.26398          \n",
      "Epoch 00006: norm_gini_val improved from 0.26316 to 0.26398, saving model to keras/keras-5fold-run-01-v1-fold-04-run-07.check\n",
      " - 134s - loss: 0.1530 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 7/100\n",
      "roc_auc: 0.64366 - roc_auc_val: 0.63154 - norm_gini: 0.28731 - norm_gini_val: 0.26307          \n",
      "Epoch 00007: norm_gini_val did not improve\n",
      " - 134s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 8/100\n",
      "roc_auc: 0.64605 - roc_auc_val: 0.63205 - norm_gini: 0.2921 - norm_gini_val: 0.2641          \n",
      "Epoch 00008: norm_gini_val improved from 0.26398 to 0.26410, saving model to keras/keras-5fold-run-01-v1-fold-04-run-07.check\n",
      " - 135s - loss: 0.1527 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 9/100\n",
      "roc_auc: 0.64727 - roc_auc_val: 0.63377 - norm_gini: 0.29455 - norm_gini_val: 0.26755          \n",
      "Epoch 00009: norm_gini_val improved from 0.26410 to 0.26755, saving model to keras/keras-5fold-run-01-v1-fold-04-run-07.check\n",
      " - 134s - loss: 0.1526 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 10/100\n",
      "roc_auc: 0.64878 - roc_auc_val: 0.63299 - norm_gini: 0.29756 - norm_gini_val: 0.26599          \n",
      "Epoch 00010: norm_gini_val did not improve\n",
      " - 132s - loss: 0.1525 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 11/100\n",
      "roc_auc: 0.64929 - roc_auc_val: 0.63173 - norm_gini: 0.29859 - norm_gini_val: 0.26346          \n",
      "Epoch 00011: norm_gini_val did not improve\n",
      " - 132s - loss: 0.1525 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9636\n",
      "Epoch 12/100\n",
      "roc_auc: 0.65141 - roc_auc_val: 0.63237 - norm_gini: 0.30282 - norm_gini_val: 0.26474          \n",
      "Epoch 00012: norm_gini_val did not improve\n",
      " - 130s - loss: 0.1523 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "roc_auc: 0.65187 - roc_auc_val: 0.63231 - norm_gini: 0.30375 - norm_gini_val: 0.26463          \n",
      "Epoch 00013: norm_gini_val did not improve\n",
      " - 133s - loss: 0.1523 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 14/100\n",
      "roc_auc: 0.65293 - roc_auc_val: 0.63287 - norm_gini: 0.30586 - norm_gini_val: 0.26573          \n",
      "Epoch 00014: norm_gini_val did not improve\n",
      " - 133s - loss: 0.1523 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 15/100\n",
      "roc_auc: 0.65449 - roc_auc_val: 0.63394 - norm_gini: 0.30898 - norm_gini_val: 0.26787          \n",
      "Epoch 00015: norm_gini_val improved from 0.26755 to 0.26787, saving model to keras/keras-5fold-run-01-v1-fold-04-run-07.check\n",
      " - 133s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 16/100\n",
      "roc_auc: 0.6559 - roc_auc_val: 0.6331 - norm_gini: 0.31181 - norm_gini_val: 0.2662          \n",
      "Epoch 00016: norm_gini_val did not improve\n",
      " - 133s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 17/100\n",
      "roc_auc: 0.65521 - roc_auc_val: 0.63251 - norm_gini: 0.31043 - norm_gini_val: 0.26502          \n",
      "Epoch 00017: norm_gini_val did not improve\n",
      " - 134s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 18/100\n",
      "roc_auc: 0.65766 - roc_auc_val: 0.6314 - norm_gini: 0.31531 - norm_gini_val: 0.2628          \n",
      "Epoch 00018: norm_gini_val did not improve\n",
      " - 133s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9636\n",
      "Epoch 19/100\n",
      "roc_auc: 0.65712 - roc_auc_val: 0.63066 - norm_gini: 0.31424 - norm_gini_val: 0.26131          \n",
      "Epoch 00019: norm_gini_val did not improve\n",
      " - 130s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9636\n",
      "Epoch 20/100\n",
      "roc_auc: 0.65515 - roc_auc_val: 0.63141 - norm_gini: 0.3103 - norm_gini_val: 0.26281          \n",
      "Epoch 00020: norm_gini_val did not improve\n",
      " - 135s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1529 - val_acc: 0.9636\n",
      "Epoch 21/100\n",
      "roc_auc: 0.65726 - roc_auc_val: 0.63224 - norm_gini: 0.31452 - norm_gini_val: 0.26448          \n",
      "Epoch 00021: norm_gini_val did not improve\n",
      " - 133s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 22/100\n",
      "roc_auc: 0.65887 - roc_auc_val: 0.63097 - norm_gini: 0.31773 - norm_gini_val: 0.26194          \n",
      "Epoch 00022: norm_gini_val did not improve\n",
      " - 134s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 23/100\n",
      "roc_auc: 0.6592 - roc_auc_val: 0.63132 - norm_gini: 0.31839 - norm_gini_val: 0.26263          \n",
      "Epoch 00023: norm_gini_val did not improve\n",
      " - 134s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9636\n",
      "Epoch 24/100\n",
      "roc_auc: 0.66034 - roc_auc_val: 0.63087 - norm_gini: 0.32068 - norm_gini_val: 0.26175          \n",
      "Epoch 00024: norm_gini_val did not improve\n",
      " - 134s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 25/100\n",
      "roc_auc: 0.65958 - roc_auc_val: 0.63102 - norm_gini: 0.31917 - norm_gini_val: 0.26205          \n",
      "Epoch 00025: norm_gini_val did not improve\n",
      " - 134s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 00025: early stopping\n",
      "Run 6, Fold 3, Score: 0.2679\n",
      "Train on 476171 samples, validate on 119041 samples\n",
      "Epoch 1/100\n",
      "roc_auc: 0.63046 - roc_auc_val: 0.62462 - norm_gini: 0.26091 - norm_gini_val: 0.24924          \n",
      "Epoch 00001: norm_gini_val improved from -inf to 0.24924, saving model to keras/keras-5fold-run-01-v1-fold-05-run-07.check\n",
      " - 170s - loss: 0.1813 - acc: 0.9537 - val_loss: 0.1529 - val_acc: 0.9636\n",
      "Epoch 2/100\n",
      "roc_auc: 0.63535 - roc_auc_val: 0.62776 - norm_gini: 0.27069 - norm_gini_val: 0.25551          \n",
      "Epoch 00002: norm_gini_val improved from 0.24924 to 0.25551, saving model to keras/keras-5fold-run-01-v1-fold-05-run-07.check\n",
      " - 138s - loss: 0.1548 - acc: 0.9635 - val_loss: 0.1529 - val_acc: 0.9636\n",
      "Epoch 3/100\n",
      "roc_auc: 0.63692 - roc_auc_val: 0.62758 - norm_gini: 0.27384 - norm_gini_val: 0.25516          \n",
      "Epoch 00003: norm_gini_val did not improve\n",
      " - 137s - loss: 0.1539 - acc: 0.9636 - val_loss: 0.1530 - val_acc: 0.9636\n",
      "Epoch 4/100\n",
      "roc_auc: 0.64018 - roc_auc_val: 0.6307 - norm_gini: 0.28036 - norm_gini_val: 0.26139          \n",
      "Epoch 00004: norm_gini_val improved from 0.25551 to 0.26139, saving model to keras/keras-5fold-run-01-v1-fold-05-run-07.check\n",
      " - 128s - loss: 0.1536 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 5/100\n",
      "roc_auc: 0.6411 - roc_auc_val: 0.62964 - norm_gini: 0.2822 - norm_gini_val: 0.25927          \n",
      "Epoch 00005: norm_gini_val did not improve\n",
      " - 134s - loss: 0.1533 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 6/100\n",
      "roc_auc: 0.64325 - roc_auc_val: 0.63042 - norm_gini: 0.28649 - norm_gini_val: 0.26085          \n",
      "Epoch 00006: norm_gini_val did not improve\n",
      " - 136s - loss: 0.1531 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 7/100\n",
      "roc_auc: 0.64282 - roc_auc_val: 0.63121 - norm_gini: 0.28564 - norm_gini_val: 0.26242          \n",
      "Epoch 00007: norm_gini_val improved from 0.26139 to 0.26242, saving model to keras/keras-5fold-run-01-v1-fold-05-run-07.check\n",
      " - 136s - loss: 0.1530 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 8/100\n",
      "roc_auc: 0.64532 - roc_auc_val: 0.63178 - norm_gini: 0.29065 - norm_gini_val: 0.26355          \n",
      "Epoch 00008: norm_gini_val improved from 0.26242 to 0.26355, saving model to keras/keras-5fold-run-01-v1-fold-05-run-07.check\n",
      " - 136s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 9/100\n",
      "roc_auc: 0.64709 - roc_auc_val: 0.63143 - norm_gini: 0.29418 - norm_gini_val: 0.26286          \n",
      "Epoch 00009: norm_gini_val did not improve\n",
      " - 128s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 10/100\n",
      "roc_auc: 0.64833 - roc_auc_val: 0.63218 - norm_gini: 0.29667 - norm_gini_val: 0.26435          \n",
      "Epoch 00010: norm_gini_val improved from 0.26355 to 0.26435, saving model to keras/keras-5fold-run-01-v1-fold-05-run-07.check\n",
      " - 137s - loss: 0.1526 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 11/100\n",
      "roc_auc: 0.64946 - roc_auc_val: 0.63056 - norm_gini: 0.29892 - norm_gini_val: 0.26111          \n",
      "Epoch 00011: norm_gini_val did not improve\n",
      " - 138s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 12/100\n",
      "roc_auc: 0.64998 - roc_auc_val: 0.62947 - norm_gini: 0.29995 - norm_gini_val: 0.25895          \n",
      "Epoch 00012: norm_gini_val did not improve\n",
      " - 140s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 13/100\n",
      "roc_auc: 0.65113 - roc_auc_val: 0.63111 - norm_gini: 0.30227 - norm_gini_val: 0.26221          \n",
      "Epoch 00013: norm_gini_val did not improve\n",
      " - 134s - loss: 0.1523 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 14/100\n",
      "roc_auc: 0.65267 - roc_auc_val: 0.63098 - norm_gini: 0.30534 - norm_gini_val: 0.26195          \n",
      "Epoch 00014: norm_gini_val did not improve\n",
      " - 136s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 15/100\n",
      "roc_auc: 0.65307 - roc_auc_val: 0.63059 - norm_gini: 0.30614 - norm_gini_val: 0.26118          \n",
      "Epoch 00015: norm_gini_val did not improve\n",
      " - 136s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 16/100\n",
      "roc_auc: 0.65467 - roc_auc_val: 0.63052 - norm_gini: 0.30934 - norm_gini_val: 0.26104          \n",
      "Epoch 00016: norm_gini_val did not improve\n",
      " - 109s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 17/100\n",
      "roc_auc: 0.65556 - roc_auc_val: 0.62984 - norm_gini: 0.31111 - norm_gini_val: 0.25969          \n",
      "Epoch 00017: norm_gini_val did not improve\n",
      " - 104s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 18/100\n",
      "roc_auc: 0.65616 - roc_auc_val: 0.62973 - norm_gini: 0.31233 - norm_gini_val: 0.25947          \n",
      "Epoch 00018: norm_gini_val did not improve\n",
      " - 104s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 19/100\n",
      "roc_auc: 0.65664 - roc_auc_val: 0.62991 - norm_gini: 0.31329 - norm_gini_val: 0.25982          \n",
      "Epoch 00019: norm_gini_val did not improve\n",
      " - 104s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 20/100\n",
      "roc_auc: 0.65727 - roc_auc_val: 0.63028 - norm_gini: 0.31453 - norm_gini_val: 0.26056          \n",
      "Epoch 00020: norm_gini_val did not improve\n",
      " - 105s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 00020: early stopping\n",
      "Run 6, Fold 4, Score: 0.2644\n",
      "CV Score: 0.2679 +- 0.0040\n"
     ]
    }
   ],
   "source": [
    "# Let's split the data into folds. I always use the same random number for reproducibility, \n",
    "# and suggest that you do the same (you certainly don't have to use 1001).\n",
    "\n",
    "cv_splits = 5\n",
    "\n",
    "if False:\n",
    "    df_preds_keras = pd.DataFrame(df_test.copy()['id'])\n",
    "    df_preds_keras.to_csv('Predictions/Base/keras/test.csv', index = False)\n",
    "    df_preds_train_keras = pd.DataFrame(df_train.copy()['id'])\n",
    "    df_preds_train_keras.to_csv('Predictions/Base/keras/train.csv', index = False)\n",
    "\n",
    "starttime = timer(None)\n",
    "for i in range(6, 7):\n",
    "    skf = StratifiedKFold(n_splits=cv_splits, random_state=600+i)\n",
    "    \n",
    "    preds_keras = np.zeros(len(df_test))\n",
    "    preds_tr_keras = np.zeros(len(df_train))\n",
    "    cv_scores = []\n",
    "\n",
    "    for j, (train_index, test_index) in enumerate(skf.split(train, target)):\n",
    "        X_train, X_val = train[train_index], train[test_index]\n",
    "        y_train, y_val = target[train_index], target[test_index]\n",
    "        train_ids, val_ids = tr_ids[train_index], tr_ids[test_index]\n",
    "\n",
    "        # This is where we define and compile the model. These parameters are not optimal, as they were chosen \n",
    "        # to get a notebook to complete in 60 minutes. Other than leaving BatchNormalization and last sigmoid \n",
    "        # activation alone, virtually everything else can be optimized: number of neurons, types of initializers, \n",
    "        # activation functions, dropout values. The same goes for the optimizer at the end.\n",
    "\n",
    "        # This definition must be within the for loop or else it will continue training previous model\n",
    "        def baseline_model():\n",
    "            model = Sequential()\n",
    "            model.add(Dense(200, input_dim=X_train.shape[1], kernel_initializer='glorot_normal',))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(100, kernel_initializer='glorot_normal'))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(0.25))\n",
    "            model.add(Dense(50, kernel_initializer='glorot_normal'))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(0.15))\n",
    "            model.add(Dense(25, kernel_initializer='glorot_normal'))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(0.1))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            # Compile model\n",
    "            model.compile(optimizer='adam', metrics = ['accuracy'], loss='binary_crossentropy')\n",
    "\n",
    "            return model\n",
    "        np.random.seed()\n",
    "\n",
    "    # Lots to unpack here.\n",
    "\n",
    "    # The first callback prints out roc_auc and gini values at the end of each epoch. It must be listed \n",
    "    # before the EarlyStopping callback, which monitors gini values saved in the previous callback. Make \n",
    "    # sure to set the mode to \"max\" because the default value (\"auto\") will not handle gini properly \n",
    "    # (it will act as if the model is not improving even when roc/gini go up).\n",
    "\n",
    "    # CSVLogger creates a record of all iterations. Not really needed but it doesn't hurt to have it.\n",
    "\n",
    "    # ModelCheckpoint saves a model each time gini improves. Its mode also must be set to \"max\" for reasons \n",
    "    # explained above.\n",
    "\n",
    "        callbacks = [\n",
    "            roc_auc_callback(training_data=(X_train, y_train),validation_data=(X_val, y_val)),  # call this before EarlyStopping\n",
    "            EarlyStopping(monitor='norm_gini_val', patience=patience, mode='max', verbose=1),\n",
    "            CSVLogger('keras/keras-5fold-run-01-v1-epochs.log', separator=',', append=False),\n",
    "            ModelCheckpoint(\n",
    "                    'keras/keras-5fold-run-01-v1-fold-' + str('%02d' % (j + 1)) + '-run-' + str('%02d' % (i + 1)) + '.check',\n",
    "                    monitor='norm_gini_val', mode='max', # mode must be set to max or Keras will be confused\n",
    "                    save_best_only=True,\n",
    "                    verbose=1)\n",
    "        ]\n",
    "        nnet = KerasClassifier(build_fn=baseline_model, epochs=100, batch_size=batchsize,\n",
    "                               validation_data=(X_val, y_val), verbose=2, shuffle=True, callbacks=callbacks)\n",
    "\n",
    "        fit = nnet.fit(X_train, y_train)\n",
    "\n",
    "        # We want the best saved model - not the last one where the training stopped. So we delete the old \n",
    "        # model instance and load the model from the last saved checkpoint. Next we predict values both for \n",
    "        # validation and test data, and create a summary of parameters for each run.\n",
    "\n",
    "        del nnet\n",
    "        nnet = load_model('keras/keras-5fold-run-01-v1-fold-' + str('%02d' % (j + 1)) + '-run-' + str('%02d' % (i + 1)) + '.check')\n",
    "\n",
    "        preds_valid = nnet.predict_proba(X_val, verbose=0).ravel()\n",
    "        preds_tr_keras[test_index] += preds_valid\n",
    "        cv_scores.append(gini_normalized(y_val, preds_valid))\n",
    "        preds_keras += nnet.predict(test).ravel() / cv_splits\n",
    "        print('Run {}, Fold {}, Score: {:0.4f}'.format(i, j, cv_scores[-1]))\n",
    "\n",
    "    print('CV Score: {:0.4f} +- {:0.4f}'.format(np.mean(cv_scores), np.std(cv_scores)))\n",
    "    \n",
    "    df_preds_keras = pd.read_csv('Predictions/Base/keras/test.csv')\n",
    "    df_preds_keras[str(i)] = preds_keras\n",
    "    df_preds_keras.to_csv('Predictions/Base/keras/test.csv', index = False)\n",
    "\n",
    "    df_preds_train_keras = pd.read_csv('Predictions/Base/keras/train.csv')\n",
    "    df_preds_train_keras[str(i)] = preds_tr_keras\n",
    "    df_preds_train_keras.to_csv('Predictions/Base/keras/train.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGF with 20 nonlinear features\n",
    "https://www.kaggle.com/lscoelho/rgf-with-20-nonlinear-features/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.1 \n",
      "Run 7, Fold 4, Score: 0.2915\n",
      " \n",
      "Run 7, Fold 4, Score: 0.2708\n",
      " \n",
      "Run 7, Fold 4, Score: 0.2807\n",
      " \n",
      "Run 7, Fold 4, Score: 0.2650\n",
      " \n",
      "Run 7, Fold 4, Score: 0.3126\n",
      " \n",
      "Run 7, Fold 4, Score: 0.3022\n",
      " \n",
      "Run 7, Fold 4, Score: 0.2504\n",
      " \n",
      "Run 7, Fold 4, Score: 0.2915\n",
      " \n",
      "Run 7, Fold 4, Score: 0.2857\n",
      " \n",
      "Run 7, Fold 4, Score: 0.2800\n",
      "CV Score: 0.2831 +- 0.0172\n",
      "\n",
      "Finished ...\n",
      "Total time 360.4914371172587 min\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Starter code for RGF implemented by Leandro dos Santos Coelho\n",
    "# Source code modified based on RGF + Target Encoding + Upsampling, Bojan Tunguz, \n",
    "# https://www.kaggle.com/tunguz/rgf-target-encoding-0-282-on-lb , version 8\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rgf.sklearn import RGFClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit\n",
    "import time\n",
    "import gc\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "tcurrent   = start_time\n",
    "\n",
    "np.random.seed(31143)  \n",
    "\n",
    "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None,    # Revised to encode validation series\n",
    "                  val_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_val_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=val_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_val_series.index = val_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)\n",
    "    \n",
    "# Read data\n",
    "train_df = pd.read_csv('train.csv', na_values=\"-1\") # .iloc[0:200,:]\n",
    "test_df = pd.read_csv('test.csv', na_values=\"-1\")\n",
    "\n",
    "#---- begin FEATURE ENGINEERING: NONLINEAR feature engineering by Leandro dos Santos Coelho\n",
    "# train\n",
    "train_df['v001'] = train_df[\"ps_ind_03\"]+train_df[\"ps_ind_14\"]+np.square(train_df[\"ps_ind_15\"])\n",
    "train_df['v002'] = train_df[\"ps_ind_03\"]+train_df[\"ps_ind_14\"]+np.tanh(train_df[\"ps_ind_15\"])\n",
    "train_df['v003'] = train_df[\"ps_reg_01\"]+train_df[\"ps_reg_02\"]**3+train_df[\"ps_reg_03\"]\n",
    "train_df['v004'] = train_df[\"ps_reg_01\"]**2.15+np.tanh(train_df[\"ps_reg_02\"])+train_df[\"ps_reg_03\"]**3.1\n",
    "train_df['v005'] = train_df[\"ps_calc_01\"]+train_df[\"ps_calc_13\"]+np.tanh(train_df[\"ps_calc_14\"])\n",
    "train_df['v006'] = train_df[\"ps_car_13\"]+np.tanh(train_df[\"v003\"])\n",
    "train_df['v007'] = train_df[\"ps_car_13\"]+train_df[\"v002\"]**2.7\n",
    "train_df['v008'] = train_df[\"ps_car_13\"]+train_df[\"v003\"]**3.4\n",
    "train_df['v009'] = train_df[\"ps_car_13\"]+train_df[\"v004\"]**3.1\n",
    "train_df['v010'] = train_df[\"ps_car_13\"]+train_df[\"v005\"]**2.3\n",
    "\n",
    "train_df['v011'] = train_df[\"ps_ind_03\"]**2.1+train_df[\"ps_ind_14\"]**0.45+train_df[\"ps_ind_15\"]**2.4\n",
    "train_df['v012'] = train_df[\"ps_ind_03\"]**2.56+train_df[\"ps_calc_13\"]**2.15+train_df[\"ps_reg_01\"]**2.3\n",
    "train_df['v013'] = train_df[\"v003\"]**2.15+train_df[\"ps_reg_01\"]**2.49+train_df[\"ps_ind_15\"]**2.14\n",
    "train_df['v014'] = train_df[\"v009\"]**2.36+train_df[\"ps_calc_01\"]**2.25+train_df[\"ps_reg_01\"]**2.36\n",
    "train_df['v015'] = train_df[\"v003\"]**3.21+0.001*np.tanh(train_df[\"ps_reg_01\"])+train_df[\"ps_ind_15\"]**3.12\n",
    "train_df['v016'] = train_df[\"v009\"]**2.13+0.001*np.tanh(train_df[\"ps_calc_01\"])+train_df[\"ps_reg_01\"]**2.13\n",
    "train_df['v017'] = train_df[\"v016\"]**2+train_df[\"v001\"]**2.1+train_df[\"v003\"]**2.3\n",
    "\n",
    "train_df['v018'] = train_df[\"v012\"]**2.3+train_df[\"v002\"]**2.3+train_df[\"v005\"]**2.31\n",
    "train_df['v019'] = train_df[\"v008\"]**2.6+train_df[\"v009\"]**2.1+train_df[\"v004\"]**2.13\n",
    "train_df['v020'] = train_df[\"v012\"]**2.7+train_df[\"v002\"]**2.2+train_df[\"v005\"]**2.43\n",
    "\n",
    "# test\n",
    "test_df['v001'] = test_df[\"ps_ind_03\"]+test_df[\"ps_ind_14\"]+np.square(test_df[\"ps_ind_15\"])\n",
    "test_df['v002'] = test_df[\"ps_ind_03\"]+test_df[\"ps_ind_14\"]+np.tanh(test_df[\"ps_ind_15\"])\n",
    "test_df['v003'] = test_df[\"ps_reg_01\"]+test_df[\"ps_reg_02\"]**3+test_df[\"ps_reg_03\"]\n",
    "test_df['v004'] = test_df[\"ps_reg_01\"]**2.15+np.tanh(test_df[\"ps_reg_02\"])+test_df[\"ps_reg_03\"]**3.1\n",
    "test_df['v005'] = test_df[\"ps_calc_01\"]+test_df[\"ps_calc_13\"]+np.tanh(test_df[\"ps_calc_14\"])\n",
    "test_df['v006'] = test_df[\"ps_car_13\"]+np.tanh(test_df[\"v003\"])\n",
    "test_df['v007'] = test_df[\"ps_car_13\"]+test_df[\"v002\"]**2.7\n",
    "test_df['v008'] = test_df[\"ps_car_13\"]+test_df[\"v003\"]**3.4\n",
    "test_df['v009'] = test_df[\"ps_car_13\"]+test_df[\"v004\"]**3.1\n",
    "test_df['v010'] = test_df[\"ps_car_13\"]+test_df[\"v005\"]**2.3\n",
    "\n",
    "test_df['v011'] = test_df[\"ps_ind_03\"]**2.1+test_df[\"ps_ind_14\"]**0.45+test_df[\"ps_ind_15\"]**2.4\n",
    "test_df['v012'] = test_df[\"ps_ind_03\"]**2.56+test_df[\"ps_calc_13\"]**2.15+test_df[\"ps_reg_01\"]**2.3\n",
    "test_df['v013'] = test_df[\"v003\"]**2.15+test_df[\"ps_reg_01\"]**2.49+test_df[\"ps_ind_15\"]**2.14\n",
    "test_df['v014'] = test_df[\"v009\"]**2.36+test_df[\"ps_calc_01\"]**2.25+test_df[\"ps_reg_01\"]**2.36\n",
    "test_df['v015'] = test_df[\"v003\"]**3.21+0.001*np.tanh(test_df[\"ps_reg_01\"])+test_df[\"ps_ind_15\"]**3.12\n",
    "test_df['v016'] = test_df[\"v009\"]**2.13+0.001*np.tanh(test_df[\"ps_calc_01\"])+test_df[\"ps_reg_01\"]**2.13\n",
    "test_df['v017'] = test_df[\"v016\"]**2+test_df[\"v001\"]**2.1+test_df[\"v003\"]**2.3\n",
    "\n",
    "test_df['v018'] = test_df[\"v012\"]**2.3+test_df[\"v002\"]**2.3+test_df[\"v005\"]**2.31\n",
    "test_df['v019'] = test_df[\"v008\"]**2.6+test_df[\"v009\"]**2.1+test_df[\"v004\"]**2.13\n",
    "test_df['v020'] = test_df[\"v012\"]**2.7+test_df[\"v002\"]**2.2+test_df[\"v005\"]**2.43\n",
    "\n",
    "#---- end FEATURE ENGINEERING: NONLINEAR feature engineering by Leandro dos Santos Coelho\n",
    "\n",
    "# from olivier\n",
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "\t\n",
    "\t\"v001\",\"v002\",\"v003\",\"v004\",\"v005\",\n",
    "\t\"v006\",\"v007\",\"v008\",\"v009\",\"v010\",   \n",
    "\t\"v011\",\"v012\",\"v013\",\"v014\",\"v015\",   \n",
    "\t\"v016\",\"v017\",\"v018\",\"v019\",\"v020\", # new nonlinear features\n",
    "]\n",
    "\n",
    "# add combinations\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]\n",
    "\n",
    "# Process data\n",
    "id_test = test_df['id'].values\n",
    "id_train = train_df['id'].values\n",
    "y = train_df['target']\n",
    "\n",
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    print('current feature %60s %4d in %5.1f'\n",
    "          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "\n",
    "    train_features.append(name1)\n",
    "    \n",
    "X = train_df[train_features]\n",
    "test_df = test_df[train_features]\n",
    "\n",
    "f_cats = [f for f in X.columns if \"_cat\" in f]\n",
    "\n",
    "\n",
    "y_valid_pred = 0*y\n",
    "y_test_pred = 0\n",
    "\n",
    "np.random.seed(11)\n",
    "\n",
    "    \n",
    "# Run CV\n",
    "\n",
    "def run_rgf():\n",
    "    model = RGFClassifier(\n",
    "        max_leaf         = 1000,  # original code with 1000 (verify the time limit to run it in Kaggle environment)\n",
    "        algorithm        = \"RGF\",  \n",
    "        loss             = \"Log\",\n",
    "        l2               = 0.011,\n",
    "        sl2              = 0.011,\n",
    "        normalize        = False,\n",
    "        min_samples_leaf = 8,   # 10,\n",
    "        n_iter           = None,\n",
    "        opt_interval     = 100,\n",
    "        learning_rate    = .4,  # .3,\n",
    "        calc_prob        = \"sigmoid\",\n",
    "        n_jobs           = -1,\n",
    "        memory_policy    = \"generous\",\n",
    "        verbose          = 0\n",
    "    )\n",
    "    \n",
    "    fit_model = model.fit( X_train, y_train )\n",
    "    pred      = fit_model.predict_proba(X_valid)[:,1]\n",
    "    pred_test = fit_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    try:\n",
    "        subprocess.call('rm -rf /tmp/rgf/*', shell=True)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "    \n",
    "    return pred, pred_test\n",
    "    \n",
    "if False:\n",
    "    df_preds_rgf20 = pd.DataFrame(df_test.copy()['id'])\n",
    "    df_preds_rgf20.to_csv('Predictions/Base/rgf20/test.csv', index = False)\n",
    "    df_preds_train_rgf20 = pd.DataFrame(df_train.copy()['id'])\n",
    "    df_preds_train_rgf20.to_csv('Predictions/Base/rgf20/train.csv', index = False)\n",
    "    \n",
    "for run in range(7, 8):\n",
    "    # Set up folds\n",
    "    K = 10 # 5 for first 7\n",
    "    kf = KFold(n_splits = K, random_state = 700+run, shuffle = True)\n",
    "    cv_scores = []\n",
    "    \n",
    "    preds_rgf20 = np.zeros(len(test_df))\n",
    "    preds_tr_rgf20 = np.zeros(len(train_df))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "\n",
    "        # Create data for this fold\n",
    "        y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "        X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n",
    "        X_test = test_df.copy()\n",
    "\n",
    "        # Enocode data\n",
    "        for f in f_cats:\n",
    "            X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n",
    "                                                            trn_series=X_train[f],\n",
    "                                                            val_series=X_valid[f],\n",
    "                                                            tst_series=X_test[f],\n",
    "                                                            target=y_train,\n",
    "                                                            min_samples_leaf=200,\n",
    "                                                            smoothing=10,\n",
    "                                                            noise_level=0\n",
    "                                                            )\n",
    "        # Run model for this fold\n",
    "        X_train = X_train.fillna(X_train.mean())\n",
    "        X_valid = X_valid.fillna(X_valid.mean())\n",
    "        X_test  = X_test.fillna(X_test.mean())\n",
    "\n",
    "        # Generate validation predictions for this fold\n",
    "        preds_valid, pred_test = run_rgf()\n",
    "        \n",
    "        preds_tr_rgf20[test_index] += preds_valid\n",
    "        cv_scores.append(gini_normalized(y_valid, preds_valid))\n",
    "        preds_rgf20 += pred_test / K\n",
    "        print(' ')\n",
    "        print('Run {}, Fold {}, Score: {:0.4f}'.format(run, i, cv_scores[-1]))\n",
    "\n",
    "        del X_test, X_train, X_valid, y_train\n",
    "\n",
    "        gc.collect()\n",
    "        gc.collect()\n",
    "        gc.collect()\n",
    "    \n",
    "    print('CV Score: {:0.4f} +- {:0.4f}'.format(np.mean(cv_scores), np.std(cv_scores)))\n",
    "    \n",
    "    df_preds_rgf20 = pd.read_csv('Predictions/Base/rgf20/test.csv')\n",
    "    df_preds_rgf20[str(run)] = preds_rgf20\n",
    "    df_preds_rgf20.to_csv('Predictions/Base/rgf20/test.csv', index = False)\n",
    "\n",
    "    df_preds_train_rgf20 = pd.read_csv('Predictions/Base/rgf20/train.csv')\n",
    "    df_preds_train_rgf20[str(run)] = preds_tr_rgf20\n",
    "    df_preds_train_rgf20.to_csv('Predictions/Base/rgf20/train.csv', index = False)\n",
    "\n",
    "    print( \"\\nFinished ...\")\n",
    "    nm=(time.time() - start_time)/60\n",
    "    print (\"Total time %s min\" % nm)\n",
    "    print('-------------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
